{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59a4826e-7392-4545-a4e5-79dbd91e2bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50ac052-2628-46cf-acfe-e01b20b5238d",
   "metadata": {},
   "source": [
    "## Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e6447fc-7e8a-4974-9106-a81223e12ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "        .appName(\"SQLClass1App\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d749b42-4afd-4b41-83ea-bc78273a6266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.5.4'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1b8aedb-73b0-42cf-8165-117aa731e658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mysql connector property for java com.mysql:mysql-connector-j:9.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9483afa-8384-4266-8b28-71fc9464b45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define MySQL credentials\n",
    "mysql_url = \"jdbc:mysql://localhost:3307/class_1\"\n",
    "mysql_user = \"root\"\n",
    "mysql_password = \"00000\"\n",
    "mysql_driver = \"com.mysql.cj.jdbc.Driver\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262b5be9-a0de-483f-86f7-d8ab7261dd44",
   "metadata": {},
   "source": [
    "# MySQL connection with spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64806466-b116-45d2-8330-5408c03d4548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30c90a81-8658-4e7f-9aaa-fb73b58190f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"select * from prices\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "460fc9c0-2ec1-497a-a95c-36b58f120b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", mysql_url) \\\n",
    "    .option(\"user\", mysql_user) \\\n",
    "    .option(\"query\", query) \\\n",
    "    .option(\"password\", mysql_password) \\\n",
    "    .option(\"driver\", \"com.mysql.cj.jdbc.Driver\") \\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4211eba9-884a-4fb6-ba4e-9a8c4270c3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mysql_read_action(query):\n",
    "    \"\"\"\n",
    "    Perform MySQL actions like read, write, update and delete\n",
    "    \"\"\"\n",
    "    return spark.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", mysql_url) \\\n",
    "    .option(\"user\", mysql_user) \\\n",
    "    .option(\"query\", query) \\\n",
    "    .option(\"password\", mysql_password) \\\n",
    "    .option(\"driver\", mysql_driver) \\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac34bda5-4942-4e15-a0c6-17ccac02cdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = mysql_read_action(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97b7234d-f659-420f-8972-12eeeef623bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----------+-----+\n",
      "|product_id|start_date|  end_date|price|\n",
      "+----------+----------+----------+-----+\n",
      "|         1|2019-02-17|2019-02-28|    5|\n",
      "|         1|2019-03-01|2019-03-22|   20|\n",
      "|         2|2019-02-01|2019-02-20|   15|\n",
      "|         2|2019-02-21|2019-03-31|   30|\n",
      "+----------+----------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304e373d-6b65-4c99-9635-4c5c162a5642",
   "metadata": {},
   "source": [
    "# SQL and Pyspark Practice NoteBook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d772cf8a-b425-46e2-a709-f7a09bddac58",
   "metadata": {},
   "source": [
    "#### Q1. Query all columns for all American cities in the CITY table with populations larger than 100000.The CountryCode for America is USA. The CITY table is described as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de20990-20bb-4a28-a043-7ea8a30e84ef",
   "metadata": {},
   "source": [
    "## pyspark solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865b376a-b77c-4ddd-8a0c-1df977e0547a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1b8996-42fd-492c-983b-91819ebf794b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = mysql_read_action(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1362abc4-3975-4d88-af84-af0cc611f52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df.filter(col('POPULATION')>100000).where(col(\"COUNTRYCODE\")==\"USA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea01c64-3cb6-4b8b-89c1-da0aed514cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393257a1-4e4e-461c-b2ee-c5f8d49652fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# another way in pyspark\n",
    "df_filtered_1 = df.filter((col('POPULATION')>100000) & (col(\"COUNTRYCODE\")==\"USA\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaaab9f5-1151-487d-babf-91fd96c8b52b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_filtered_1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01dbe89e-db45-4169-abe1-da3f4281ab3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8a2215-a3d6-42fd-91b7-5d8cb663f30e",
   "metadata": {},
   "source": [
    "1. Both filter() and where() do the same job in the DataFrame API.\n",
    "2. where() is just an alias for filter(), provided for SQL-like syntax consistency.\n",
    "3. You can use column expressions or SQL-like string conditions in both."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb148a22-3826-446e-ad7f-3a0d8b96b7f3",
   "metadata": {},
   "source": [
    "## SQL solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b74c827-9a9b-4959-bc73-1da02ed2de7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query = \"select * from CITY where COUNTRYCODE='USA' and population>100000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d36e658-bf1e-4b2b-9110-7cb93d9c991f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sql = mysql_read_action(sql_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3107b0a-6b1a-4f12-83a3-2d5de8584523",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sql.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d656ddc-656b-4fbb-a76f-addb3d78dd26",
   "metadata": {},
   "source": [
    "###  Q2. Query the NAME field for all American cities in the CITY table with populations larger than 120000.The CountryCode for America is USA. The CITY table is described as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fcce2e-e9e9-48cf-8fef-e3b3fe58995c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyspark solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62a1480-f4d3-4a51-8649-552ecc0aa22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d8250d-d37d-4762-8435-1eaee9a49bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_2 = df.select(col(\"NAME\"), col(\"POPULATION\")).filter(col(\"POPULATION\")>120000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4908e7cf-2d63-4f21-9a9d-d3d3132018c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cf62e2-92d6-40b2-a7e3-4fe2e289da46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8443e375-bf51-4bcc-93a4-ff189695d949",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query_2 = \"select name, population from city where population>120000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3c4de4-9d47-40bb-ab14-2afc8b6cf42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sql_2 = mysql_read_action(sql_query_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f9122d-f1e4-4e60-8b3a-1e128f7ca4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sql_2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c73cca8-e427-4eb2-8487-5c942af0f611",
   "metadata": {},
   "source": [
    "### Q3. Query all columns (attributes) for every row in the CITY table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b731509a-0026-4299-9ded-85d80f68a12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06d934e-0596-455f-a5a0-a410511f9daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d4b58e-ffc7-4a8b-92eb-2ad1166e854a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_3 = df.select(col(\"*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76312e9-88ce-4b31-9185-ae44ecaa696c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210a0d78-0b22-4424-9db7-9378d8e7224c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e43275a-6587-4221-9493-bdb94a08e5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query_3 = \"select * from city\"\n",
    "\n",
    "df_sql_3 = mysql_read_action(sql_query_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a69fc1d-3d65-4213-8ede-47b51efacb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sql_3.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcd47c1-e4d9-4a26-b69b-fa61c661bbd0",
   "metadata": {},
   "source": [
    "### Q4. Query all columns for a city in CITY with the ID 1661."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ba67b0-9832-4091-8cff-b5795f7e4385",
   "metadata": {},
   "outputs": [],
   "source": [
    " # spark solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a31746a-9e9c-41bf-bd6b-6fe0e8860ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b020f87-4fd4-4fcd-ba7e-0f66df7f3fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_4 = df.where(col(\"ID\")==1661)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18646188-b5a4-4fdc-a8a2-0189fe4816f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a82ff88-4b9c-45c3-809b-4f26a824bfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sql solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28991253-2245-48b1-a7cb-a804a1480bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query_4 = \"select * from city where id=1661\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf29d2a1-33ca-489a-982e-d3d82f730700",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sql4 = mysql_read_action(sql_query_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b1c772-e617-473b-813d-f071cba4586a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sql4.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0d9324-1da4-459d-b945-9b6ed48d3b14",
   "metadata": {},
   "source": [
    "### Q5. Query all attributes of every Japanese city in the CITY table. The COUNTRYCODE for Japan is  JPN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed79e58-311c-4f0d-883a-8529cf0f51eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb36a33-b932-4473-a767-d6e0035d055d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd90f0b9-bec2-4d5d-8cd8-5245d05a000e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_5 = df.select(col(\"*\")).filter(col(\"COUNTRYCODE\")==\"JPN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa53ddb1-f994-43ea-b525-c481159b920d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_5.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb5a630-2f90-447c-82bc-b4a32ad0d428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sql solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ec7ea6-3e96-4b7d-9c0c-839f62614aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query_5 = \"select * from city where countrycode='JPN'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e34052b-981c-4cdf-b5ce-58345390565a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sql_5 = mysql_read_action(sql_query_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6df79ae-4a9e-4a59-bf15-e752171b4d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sql_5.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713920c5-860f-4744-8a98-4e2638036aaf",
   "metadata": {},
   "source": [
    "###  Q6. Query the names of all the Japanese cities in the CITY table. The COUNTRYCODE for Japan is JPN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d178ce57-0144-4ff1-b03a-424890405146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sql solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ddaf66-4649-4924-89a2-d02976d46115",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query_6 = \"select name from CITY where COUNTRYCODE='JPN'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739134b9-7c6a-4d2b-8b3b-0a1b95e2c9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sql_6 = mysql_read_action(sql_query_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e9b5ce-e6f0-4b7a-9a17-4e70a1a17bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sql_6.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc789739-ac5b-41c2-b427-c819a3d105ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyspark solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d772f4-b3aa-4242-ac20-b9cf262bf8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9995ab7f-3cbf-49f1-b9fb-d9a8d5111888",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_6 = df.select(col('name')).where(col(\"countrycode\")==\"JPN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c9318c-b9a3-4fce-99ce-26e4e3310c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_6.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b60c39-73f9-4bf2-b28a-72b55e2c37a0",
   "metadata": {},
   "source": [
    "###  Q7. Query a list of CITY and STATE from the STATION table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45702c64-e3cc-4707-9d2a-df4674569c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_table_query = \"select * from station\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2635b550-6264-44e0-a7e3-82fe72a79be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_df = mysql_read_action(station_table_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b15ea9-9f7d-4d22-bbaf-2a0b97f2c4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593edd29-a848-420b-9884-1cb96878de1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142f13dd-127d-445c-9cdf-067b3cc5ab06",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query_7 = \" select city, state from station\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812539f9-04fd-45a5-b9cc-6d81638deba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sql_7 = mysql_read_action(sql_query_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c758cb20-0f23-4ee0-8729-ad032547bbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sql_7.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abee5457-7b1c-4245-80f8-8ee39af7ebef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66af9031-0fd3-4673-a336-447a9b2181a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_7 = station_df.select(col(\"city\"), col(\"state\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a68829e-df9a-4fa1-a9a3-76a2462ae59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_7.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dba4efb-52c6-4718-a9f1-5539958bd477",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_7 = station_df.selectExpr(\"city\", \"state\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d364b645-1d51-45f7-b943-b93e7f76874c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_7.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ed5fba-daf4-46cd-bb86-c3711a1591f8",
   "metadata": {},
   "source": [
    " ### Q8. Query a list of CITY names from STATION for cities that have an even ID number. Print the results in any order, but exclude duplicates from the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88916f53-5887-4384-aa40-2572efcee719",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query_8 = \" select distinct city from station where ID%2=0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29e2f35-7da2-4fcb-9783-eefd090be09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sql_8 = mysql_read_action(sql_query_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76dcfef8-fdb0-40ac-b45b-99c2820cd2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sql_8.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4120934-6fc0-4bda-9d86-0c7d201439e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17bf2ca-ece2-4fae-990a-b3f3fcf5f80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fb1c04-24d2-4bf6-8dd9-f36ab673fb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_8 = station_df.selectExpr(\"city\").distinct().filter(col(\"ID\")%2==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2bdd04-613c-469c-bc05-c66e75b7354e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_8.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa39a59-f480-4e67-8507-1b79e77b39b7",
   "metadata": {},
   "source": [
    "### Q9. Find the difference between the total number of CITY entries in the table and the number of distinct CITY entries in the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c37e483-c865-4a84-bbbb-b50bc0e7f198",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query_9 = \"select count(city) as total_number_of_cities, count(distinct city) as unique_cities, (count(city) - count(distinct city)) as difference from station\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffc1764-98b3-41bd-a06c-56180ed63bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sql_9 = mysql_read_action(sql_query_9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77ba1d8-e5a3-4826-9c2e-56aab331167b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sql_9.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205eeeb9-47b3-4781-b3c8-dbd1111b5cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyspark solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4322b4fd-d548-462a-9870-0fb4f8f8410d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_9 = station_df.selectExpr(\"count(city) as total_cities\", \n",
    "                                     \"count(distinct city) as unique_cities\",\n",
    "                                     \"count(city) - count(distinct city) as difference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf66e91-2145-4470-b13d-11c57ade7b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_9.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b367ec-95bd-4481-934d-0db4cddb5706",
   "metadata": {},
   "source": [
    "###  Q10. Query the two cities in STATION with the shortest and longest CITY names, as well as their\n",
    "### respective lengths (i.e.: number of characters in the name). If there is more than one smallest or\n",
    "### largest city, choose the one that comes first when ordered alphabetically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692b5eb9-b976-4d0b-bab6-cb3f56c852e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sql query "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846da8ec-042a-41ca-9c31-572bd63a8bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query_9_1 = \"select city, length(city) as city_length from station order by length(city) desc limit 1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f5f9e1-3c1e-49de-a221-7575b041d8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sql_9_1 = mysql_read_action(sql_query_9_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7801930-0b00-40e8-8f37-64682938cfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sql_9_1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a35292-c4fc-492a-ad9b-43f47a4e42bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query_9_2 = \"select city, length(city) as city_length from station order by length(city), city asc limit 1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d1a520-bb6b-473d-ab30-2589548b3aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sql_9_2 = mysql_read_action(sql_query_9_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b891b8-dca8-4aae-90cf-7031b218a6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sql_9_2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3279cbef-8d06-4f76-9033-d01e25d39e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyspark solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26eaf0d-127b-4d93-a903-6d448e31f89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import length\n",
    "df_filtered_9_1 = station_df.select(col(\"city\"), length(col(\"city\")).alias(\"city_length\")).orderBy(col(\"city_length\").desc()).limit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91320a8-e020-4c3f-af40-7d7fed79ce54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_9_1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecb7164-6a5a-42ef-9da3-dc470d9e7436",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_9_2 = station_df.select(col(\"city\"), length(col(\"city\")).alias(\"city_length\")).orderBy(col(\"city\")).limit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a10c639-dde2-4da4-ad51-ed4367c62ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_9_2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3265e86-ccd5-40fc-84d1-3d5fdd269bcc",
   "metadata": {},
   "source": [
    "###  Q11. Query the list of CITY names starting with vowels (i.e., a, e, i, o, or u) from STATION. Your result cannot contain duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968d233e-a4f2-4361-9a3b-fa60943195f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sql_solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af44b127-e841-4bff-a247-e999042edc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query_10 = \"SELECT DISTINCT(CITY) AS DISTINCT_CITY_NAME FROM STATION WHERE lower(SUBSTR(city,1,1)) in ('a','e','i','o','u')\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "4bb20dab-7857-4b33-8caf-cf5d2973d6d9",
   "metadata": {},
   "source": [
    "✅ Parameters:\n",
    "city: the string column you're operating on.\n",
    "\n",
    "1: the starting position (1-based index — so 1 means start from the first character).\n",
    "\n",
    "1: the length of the substring to extract (here, just 1 character)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06628485-88b8-47db-a823-6cbcfefd2d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sql_10 = mysql_read_action(sql_query_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442e7c5c-3084-4d9d-9414-bb5f06f5c4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sql_10.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a6fbbc-0ba6-4762-b248-b944c47a9367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyspark solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b82d246-8a61-47bb-aa8d-4651d6a0679f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lower\n",
    "df_filtered_11 = station_df.select(col(\"city\")).distinct().filter(lower(col('city')).substr(1, 1).isin(\"a\", \"e\", \"i\", \"o\", \"u\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70d28ac-afc7-4420-bc98-cd612bd22159",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_11.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35179641-feb4-4808-88ae-aa9b887a50ff",
   "metadata": {},
   "source": [
    "### Q12. Query the list of CITY names ending with vowels (a, e, i, o, u) from STATION. Your result cannot contain duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce47bc5-d839-4e2f-b476-d04438a6451f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query_11 = \"SELECT DISTINCT(CITY) AS DISTINCT_CITY_NAME FROM STATION WHERE lower(SUBSTR(city,-1,1)) in ('a','e','i','o','u')\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d30082-7484-499d-b6a1-293e5032308d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sql_11 = mysql_read_action(sql_query_11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94397dc3-5fbb-406b-bb86-3e60050e4991",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sql_11.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e4819f-2af1-4997-9359-590b89c241da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyspark solution\n",
    "df_filtered_12 = station_df.select(col(\"city\")).distinct().filter(lower(col('city')).substr(-1, 1).isin(\"a\", \"e\", \"i\", \"o\", \"u\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce55792-112e-468a-90cb-53f31303f12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_12.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304bacc7-baa4-4a8f-b559-27a50768091d",
   "metadata": {},
   "source": [
    "### Q13. Query the list of CITY names from STATION that do not start with vowels. Your result cannot contain duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45565ea0-150d-491b-9e9a-1b025f24a3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query_13 = \"select distinct city from station where lower(substr(city, 1, 1)) not in ('a', 'b', 'c', 'd', 'e')\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaceb8d6-4368-4d2e-b3f2-c19b326d3274",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sql_13 = mysql_read_action(sql_query_13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497295df-7a96-4bd0-b528-14a29b9477f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sql_13.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2ce152-ec87-446a-8c2b-a4dfa5053797",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, lower, substr\n",
    "\n",
    "df_filtered_13 = station_df \\\n",
    "    .select(\"city\") \\\n",
    "    .distinct() \\\n",
    "    .filter(~lower(col(\"city\")).substr(1, 1).isin(\"a\", \"e\", \"i\", \"o\", \"u\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a8dd67-6c4e-4544-865c-ced5ab7906db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_13.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b526df2-6d44-423f-8688-f6c87d55366e",
   "metadata": {},
   "source": [
    " ### Q14. Query the list of CITY names from STATION that do not end with vowels. Your result cannot contain duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d724343-bcc3-464c-811a-a74aa1688b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sql_solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf1a89c-e4d9-492c-abd1-9bdb494814c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query_14 = \"select distinct city from station where lower(substr(city, -1, 1)) not in ('a', 'e', 'i', 'o', 'u')\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc6c904-9305-4ef9-976b-6090bf0a64a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_query_14 = mysql_read_action(sql_query_14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e16d6ce-6482-452f-8852-ae33cec1dca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_query_14.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bf9fea-60bf-4fbe-8b0c-614bbf94607b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4dd4cb-5ac3-41e4-918c-b56e6c8e8860",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_14 = station_df.select(col('city'))\\\n",
    "                           .distinct()\\\n",
    "                           .filter(~lower(col('city')).substr(-1,1).isin('a', 'e', 'i', 'o', 'u'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b227d7c1-7dae-4d2b-b6e9-13ed382fdb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_14.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b5e794-a11f-4116-b1de-007f1a01c45d",
   "metadata": {},
   "source": [
    "### Q15. Query the list of CITY names from STATION that either do not start with vowels and do not end with vowels. Your result cannot contain duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b50f7e-8d6c-4540-b97a-858abc7217c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query_15 = \"select city from station where substr(lower(city), 1, 1) not in ('a', 'e', 'i', 'o', 'u') and substr(lower(city), -1, 1) not in  ('a', 'e', 'i', 'o', 'u')\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abeac9c3-016a-42f2-9acf-37f03db27917",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sql_15 = mysql_read_action(sql_query_15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7715209-5f21-441d-b927-3875bdb54bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sql_15.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45391e3e-fcd1-4599-886e-5d8b8833f4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyspsark solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e11d63-8f6c-439a-9841-72fab9f1ce04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_15 = station_df.select(col('city'))\\\n",
    "                           .distinct()\\\n",
    "                           .filter(~lower(col('city')).substr(1,1).isin('a', 'e', 'i', 'o', 'u') & ~lower(col(\"city\")).substr(-1, 1).isin('a', 'e', 'i', 'o', 'u'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5742af4-fae2-4f88-9061-bf6fcafe5197",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_15.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d09438-3db5-492f-9a91-c7cde098d5d8",
   "metadata": {},
   "source": [
    "### Q16. Query the list of CITY names from STATION that do not start with vowels or do not end with vowels. Your result cannot contain duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7689bd25-6117-4c8d-a680-d7febfd8adcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query_16 = \"select city from station where substr(lower(city), 1, 1) not in ('a', 'e', 'i', 'o', 'u') or substr(lower(city), -1, 1) not in  ('a', 'e', 'i', 'o', 'u')\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12ea4af-47d0-4f2e-bf54-183d5933bef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sql_16 = mysql_read_action(sql_query_16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f953d3d-61b1-48f6-9325-d14561d2025a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sql_16.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436f6ec3-630c-491c-8a89-519b38390b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyspark solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9742e82-8855-4376-8aa8-1a11df46be15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_16 = station_df.select(col('city'))\\\n",
    "                           .distinct()\\\n",
    "                           .filter(~lower(col('city')).substr(1,1).isin('a', 'e', 'i', 'o', 'u') | ~lower(col(\"city\")).substr(-1, 1).isin('a', 'e', 'i', 'o', 'u'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7b4956-4076-4b8d-af55-55134e3f0def",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_16.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30ac7b1-2e73-463a-a49d-c74ff4eb79f2",
   "metadata": {},
   "source": [
    "### Q17.\n",
    " Table: Product\n",
    " Column Name Type\n",
    " product_id\n",
    " int\n",
    " product_name varchar\n",
    " unit_price int\n",
    " product_id is the primary key of this table.\n",
    " Each row of this table indicates the name and the price of each product.\n",
    " Table: Sales\n",
    " Column Name Type\n",
    " seller_id\n",
    " int\n",
    " product_id\n",
    " buyer_id\n",
    " int\n",
    " int\n",
    " sale_date\n",
    " quantity\n",
    " price\n",
    " date\n",
    " int\n",
    " int\n",
    " This table has no primary key, it can have repeated rows.\n",
    " product_id is a foreign key to the Product table.\n",
    " Each row of this table contains some information about one sale.\n",
    " Write an SQL query that reports the products that were only sold in the first quarter of 2019. That is,\n",
    " between 2019-01-01 and 2019-03-31 inclusive.\n",
    " Return the result table in any order.\n",
    " The query result format is in the following example.\n",
    " Input:\n",
    " Product table:\n",
    " product_id\n",
    " 1\n",
    " product_name unit_price\n",
    " S8\n",
    " 1000\n",
    " 2\n",
    " 3\n",
    " Sales table:\n",
    " seller_id\n",
    " G4\n",
    " iPhone\n",
    " product_id\n",
    " 800\n",
    " 1400\n",
    " buyer_id\n",
    " sale_date\n",
    " quantity\n",
    " 1\n",
    " 1\n",
    " 1\n",
    " 2019-01-21\n",
    " 2\n",
    " price\n",
    " 2000\n",
    " 1\n",
    " 2\n",
    " 3\n",
    " Output:\n",
    " product_id\n",
    " 1\n",
    " 2\n",
    " 2\n",
    " 3\n",
    " product_name\n",
    " S8\n",
    " 2\n",
    " 3\n",
    " 4\n",
    " 2019-02-17\n",
    " 2019-06-02\n",
    " 2019-05-13\n",
    " 1\n",
    " 1\n",
    " 2\n",
    " 800\n",
    " 800\n",
    " 2800\n",
    " Explanation:\n",
    " The product with id 1 was only sold in the spring of 2019.\n",
    " The product with id 2 was sold in the spring of 2019 but was also sold after the spring of 2019.\n",
    " The product with id 3 was sold after spring 2019.\n",
    " We return only product 1 as it is the product that was only sold in the spring of 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e858b17-9915-41e9-b36f-710eaf572aa3",
   "metadata": {},
   "source": [
    "### 17. Write an SQL query that reports the products that were only sold in the first quarter of 2019. That is, between 2019-01-01 and 2019-03-31 inclusive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f046906-7b9d-4831-ac8e-3406ae74d368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sql query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a5ce38-5f9a-450b-9843-aa7f581542b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query_17 = \"\"\"SELECT p.product_id, p.product_name\n",
    "FROM product p\n",
    "LEFT JOIN (\n",
    "    SELECT DISTINCT product_id\n",
    "    FROM sales\n",
    "    WHERE sale_date NOT BETWEEN '2019-01-01' AND '2019-03-31'\n",
    ") s ON p.product_id = s.product_id\n",
    "WHERE s.product_id IS NULL\"\"\"\n",
    "\n",
    "# select product_id, product_name from product where product_id not in (select product_id from sales where sale_date not between \"2019-01-01\" and \"2019-03-31\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392857d4-bc49-4e2b-b565-c138676a47af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sql_17 = mysql_read_action(sql_query_17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392cc7ac-2fc6-4a4f-b964-142d8c3ee468",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sql_17.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22df03f3-0186-4853-8b50-06487027aad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_query = \"select * from product\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b88a92-1242-4de3-b366-de9ef6f7098e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_query = \"select * from sales\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caccbf91-eaac-4b0f-b953-84ef4848ad65",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_df = mysql_read_action(product_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa3337f-44d8-4f35-a297-c440bdf06552",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4824bbd-028b-46ff-87a8-d9bc57ef2e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df = mysql_read_action(sales_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64417648-989a-4c7a-b638-3a5452f80b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c4f272-b4b9-4c76-86f2-dd20b33930a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Filter sales that occurred OUTSIDE the date range\n",
    "sales_outside = sales_df.filter(~col(\"sale_date\").between(\"2019-01-01\", \"2019-03-31\")) \\\n",
    "                        .select(\"product_id\") \\\n",
    "                        .distinct()\n",
    "\n",
    "# Step 2: Join product_df with the \"sales_outside\" using left anti join\n",
    "df_filtered_17 = product_df.join(sales_outside, on=\"product_id\", how=\"left_anti\") \\\n",
    "                      .select(\"product_id\", \"product_name\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1485f69-08dc-4cb5-a7af-3fd9f84b2e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_17.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284f0ca3-f31e-4756-ac00-cdc5d9d6e433",
   "metadata": {},
   "source": [
    "### 18. Write an SQL query to find all the authors that viewed at least one of their own articles. Return the result table sorted by id in ascending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa4ba43-0d72-4f0e-9a8b-1bc3c8e024d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query_18 = \"select distinct author_id from views where author_id=viewer_id order by author_id asc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a653a631-5d84-4c5e-877d-03a251d446d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sql_18 = mysql_read_action(sql_query_18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d98259-87dd-48b7-ae07-65f1edf7e350",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sql_18.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f799129-c0d2-4f72-8677-51ad3c82129d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyspark solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13154ec7-07d3-428c-b646-272591c9e294",
   "metadata": {},
   "outputs": [],
   "source": [
    "views_query = \"select * from views\"\n",
    "views_df = mysql_read_action(views_query)\n",
    "views_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b976b0-8c48-492f-a350-293eb6093a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_18 = views_df.select(col(\"author_id\")) \\\n",
    "                         .filter(col('author_id')==col(\"viewer_id\")) \\\n",
    "                         .distinct()\\\n",
    "                         .orderBy(col('author_id').asc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e76a4b-0158-44fc-8619-dd8829564bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_18.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d775829b-8f17-4cbf-863f-0698dfb66a7e",
   "metadata": {},
   "source": [
    "### 19. delivery_id is the primary key of this table. The table holds information about food delivery to customers that make orders at some date and specify a preferred delivery date (on the same order date or after it). If the customer's preferred delivery date is the same as the order date, then the order is called immediately; otherwise, it is called scheduled.\n",
    "### Write an SQL query to find the percentage of immediate orders in the table, rounded to 2 decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdcc067-cbae-4a42-a62a-5f15bc18194a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query_19 = \"\"\"\n",
    "SELECT \n",
    "    ROUND(\n",
    "        100.0 * SUM(CASE WHEN order_date = customer_pref_delivery_date THEN 1 ELSE 0 END) \n",
    "        / COUNT(*), \n",
    "        2\n",
    "    ) AS immediate_percentage\n",
    "FROM Delivery\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b1f0d4-038c-45c9-8fe5-a5d3b1808acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sql_19 = mysql_read_action(sql_query_19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7b40ea-a8da-462e-8f9b-bc788b9733db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sql_19.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04dc38af-abf3-4f4b-a115-cf4cdcef398e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5636fa5b-559e-4da9-9097-5f1f452c6699",
   "metadata": {},
   "outputs": [],
   "source": [
    "delivery_query = \"select * from delivery\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb08cef-7ff7-4974-9333-51cc1a380608",
   "metadata": {},
   "outputs": [],
   "source": [
    "delivery_df = mysql_read_action(delivery_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10018632-d75e-4854-825d-e8b2d1152d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "delivery_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05669bd6-a1c8-44e6-b3b1-e4d01ae73b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when, sum, count, round\n",
    "delivery_df1 = delivery_df.withColumn(\"is_immediate\",\n",
    "                                     when(col('order_date') == col('customer_pref_delivery_date'), 1).otherwise(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ececeeef-d2d9-4be9-a652-33e62b4da642",
   "metadata": {},
   "outputs": [],
   "source": [
    "delivery_df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9561c3ce-ea77-4cd7-9310-e0507d37e52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_19 = delivery_df1.select(round(100*(sum(col(\"is_immediate\"))/count('delivery_id')), 2).alias(\"delivery_percentage\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6510a19-039f-4784-8e45-6fed0507eaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_19.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d23950-60a9-42af-93dd-a4ae8e90ea29",
   "metadata": {},
   "source": [
    "### 20. Write an SQL query to find the ctr of each Ad. Round ctr to two decimal points.Return the result table ordered by ctr in descending order and by ad_id in ascending order in case of a tie."
   ]
  },
  {
   "cell_type": "raw",
   "id": "970e0589-e1dd-42da-8157-ffb6467c54ff",
   "metadata": {},
   "source": [
    " Explanation:\n",
    " for ad_id = 1, ctr = (2/(2+1)) * 100 = 66.67\n",
    " for ad_id = 2, ctr = (1/(1+2)) * 100 = 33.33\n",
    " for ad_id = 3, ctr = (1/(1+1)) * 100 = 50.00\n",
    " for ad_id = 5, ctr = 0.00, Note that ad_id = 5 has no clicks or views.\n",
    " Note that we do not care about Ignored Ads.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3027fa-28b1-4632-88e6-2d8fae65ba6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query_20 = \"\"\"select \n",
    "b.ad_id,\n",
    "round(case when (b.total_clicks+b.total_views) = 0 then 0 else 100*(b.total_clicks/(b.total_clicks+b.total_views)) end,2) as ctr\n",
    "from\n",
    "(select \n",
    "ad_id,\n",
    "sum(case when action=\"Clicked\" then 1 else 0 end) as total_clicks,\n",
    "sum(case when action=\"Viewed\" then 1 else 0 end) as total_views\n",
    "from ads group by ad_id) as b\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83b3501-1eca-4d6e-8ef6-186ae20a0a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sql_20 = mysql_read_action(sql_query_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef26759-2fd9-4950-a43c-5cef6a4fe06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sql_20.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0cc28b-2637-4ac6-959e-56454ed8068b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa59a6dc-3059-44c2-a6a6-51188ae09b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "ads_query = \"select * from ads\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972f2462-5da6-488e-afdc-bf124d7447bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ads_df = mysql_read_action(ads_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b47a7c-d5a4-420d-aa03-6f4916b0885b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ads_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87803bac-9309-4d62-bda6-fc2d37de3def",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51d8a17-d786-43cb-8157-31d93dc390b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when, sum as _sum\n",
    "df_filtered_20_1 = ads_df.groupby(col(\"ad_id\")).agg(_sum(when(col(\"action\") ==\"Clicked\", 1).otherwise(0)).alias(\"total_clicks\"))\n",
    "df_filtered_20_2 = ads_df.groupby(col(\"ad_id\")).agg(_sum(when(col(\"action\") ==\"Viewed\", 1).otherwise(0)).alias(\"total_views\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27c5667-a10b-4379-a494-556d1f450bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_20_1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f2961f-8661-4d06-b990-08b529084b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_20_2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf80695-bb55-416c-a8dc-1bbab2bc8c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_20_3 = df_filtered_20_1.join(df_filtered_20_2, on=\"ad_id\", how=\"left\").select(col(\"ad_id\"), col(\"total_clicks\"), col(\"total_views\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab8d6c1-6d2c-43d1-88a9-ac16b7bfa0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_20_3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c94e340-2eae-47ab-a92b-77699c8a97b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_20 = df_filtered_20_3.withColumn(\"ctr\",\n",
    "                                            round(when(col(\"total_clicks\")+col(\"total_views\") == 0, 0).otherwise(100 * col('total_clicks')/(col('total_clicks')+col('total_views'))), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d15c93-46f4-4f10-896b-b0ccc557c9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_20.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2c713b-7c67-473f-b04e-7c6a60455886",
   "metadata": {},
   "source": [
    "### 21.  Write an SQL query to find the team size of each of the employees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47971a65-9f38-4c6e-a020-250e4b27a231",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query_21 = \"\"\"\n",
    "select \n",
    "employee_id,\n",
    "count(employee_id) over (partition by team_id) as team_size\n",
    "from employee order by team_size desc\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "752c8820-134d-4afb-aeae-9a31fc0c50a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_query_21 = mysql_read_action(sql_query_21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "393635c3-4986-46e6-8e4b-324ba9a2f86a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+\n",
      "|employee_id|team_size|\n",
      "+-----------+---------+\n",
      "|          1|        3|\n",
      "|          2|        3|\n",
      "|          3|        3|\n",
      "|          5|        2|\n",
      "|          6|        2|\n",
      "|          4|        1|\n",
      "+-----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_query_21.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68d6f2e5-cde7-4359-9d3b-7ee7efe65750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc0f8c84-17e3-4de8-b4d4-84bf7766c8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_query = \"select * from employee\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2054439e-94c1-4830-ad6c-cbe8b448bc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df = mysql_read_action(employee_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ae9d7e0-6983-4781-953a-4310936db8bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+\n",
      "|employee_id|team_id|\n",
      "+-----------+-------+\n",
      "|          1|      8|\n",
      "|          2|      8|\n",
      "|          3|      8|\n",
      "|          4|      7|\n",
      "|          5|      9|\n",
      "|          6|      9|\n",
      "+-----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employee_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d27b938-c663-4f60-8c3e-9b6b9913b76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import col, count, sum\n",
    "window_fun_21 = Window.partitionBy(\"team_id\")\n",
    "df_filtered_21 = employee_df.withColumn(\"team_size\", count(\"team_id\").over(window_fun_21)).orderBy(\"employee_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "498775b4-6260-48ab-83fe-4f6d66794d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+---------+\n",
      "|employee_id|team_id|team_size|\n",
      "+-----------+-------+---------+\n",
      "|          1|      8|        3|\n",
      "|          2|      8|        3|\n",
      "|          3|      8|        3|\n",
      "|          4|      7|        1|\n",
      "|          5|      9|        2|\n",
      "|          6|      9|        2|\n",
      "+-----------+-------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_filtered_21.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a271717-8aef-4c68-b1e3-82cc90826981",
   "metadata": {},
   "source": [
    "### 22 --Write an SQL query to find the type of weather in each country for November 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2ef560-eeed-4d94-aa11-e985bc841b87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb11713-e6df-4188-986a-c6ca8965f8be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "06d8b17c-4144-465e-82b3-ee20fa8c2fef",
   "metadata": {},
   "source": [
    "### 23. Write an SQL query to find the average selling price for each product. average_price should be rounded to 2 decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93aa4a74-688b-44a1-bbe3-cdd75a04973a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query_23 = \"\"\"\n",
    "select \n",
    "u.product_id,\n",
    "round(sum(p.price * u.units)/sum(u.units), 2) as avg_prices\n",
    "from UnitsSold u left join prices p on (u.product_id=p.product_id \n",
    "\t\t\t\t\t\t\t\t\t\tand u.purchase_date >= p.start_date\n",
    "                                        and u.purchase_date <= p.end_date) group by u.product_id\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b764767-b269-4758-bf65-e40c56e84ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_23 = mysql_read_action(sql_query_23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e19841f-68f0-4be3-bfbe-c112df1963ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|product_id|avg_prices|\n",
      "+----------+----------+\n",
      "|         1|      6.96|\n",
      "|         2|     16.96|\n",
      "+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_filtered_23.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a0eff903-49d5-4a6c-9f4e-a3bcb98680a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyspark solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9e46a66-5480-4182-931d-54dddb9c1578",
   "metadata": {},
   "outputs": [],
   "source": [
    "prices_query = \"select * from prices\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "60b6e77f-1810-46c8-a86e-8edd27580a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prices_df = mysql_read_action(prices_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a857fcf3-5e82-4990-9eea-3f2dd2d3e5d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----------+-----+\n",
      "|product_id|start_date|  end_date|price|\n",
      "+----------+----------+----------+-----+\n",
      "|         1|2019-02-17|2019-02-28|    5|\n",
      "|         1|2019-03-01|2019-03-22|   20|\n",
      "|         2|2019-02-01|2019-02-20|   15|\n",
      "|         2|2019-02-21|2019-03-31|   30|\n",
      "+----------+----------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prices_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ee2a865e-9bfd-4605-8af1-e30a102d3290",
   "metadata": {},
   "outputs": [],
   "source": [
    "unitsSold_query = \"select * from unitssold\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e6e02b1e-680b-445e-9e2b-1e5557ed7f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "unitsSold_df = mysql_read_action(unitsSold_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "675379db-c1a1-4998-ae18-6e169c74132d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+-----+\n",
      "|product_id|purchase_date|units|\n",
      "+----------+-------------+-----+\n",
      "|         1|   2019-02-25|  100|\n",
      "|         1|   2019-03-01|   15|\n",
      "|         2|   2019-02-10|  200|\n",
      "|         2|   2019-03-22|   30|\n",
      "+----------+-------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "unitsSold_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "df0ddd02-8f6e-4083-b102-50470b251193",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, sum as _sum, round\n",
    "df_filtered_23_1 = unitsSold_df.join(prices_df, ((unitsSold_df[\"product_id\"]==prices_df[\"product_id\"]) & \\\n",
    "                                                (unitsSold_df.purchase_date>=prices_df.start_date) & \\\n",
    "                                                (unitsSold_df.purchase_date <= prices_df.end_date)), how=\"left\") \\\n",
    "                                                .groupBy(unitsSold_df.product_id) \\\n",
    "                                                .agg(round(_sum(unitsSold_df.units*prices_df.price)/_sum(unitsSold_df.units), 2).alias(\"avg_price\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8f84be28-422f-4ca3-a009-71c8f70ddf5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+\n",
      "|product_id|avg_price|\n",
      "+----------+---------+\n",
      "|         1|     6.96|\n",
      "|         2|    16.96|\n",
      "+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_filtered_23_1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49a6f4b-645a-4091-ab61-802bbe2243f3",
   "metadata": {},
   "source": [
    "### 24.Write an SQL query to report the first login date for each player."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "90eacdbd-9fa7-4be0-8e30-0268527907b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query_24 = \"\"\"\n",
    "select * from (\n",
    "select \n",
    "a.player_id,\n",
    "a.event_date as first_login,\n",
    "row_number() over(partition by a.player_id) as row_num\n",
    "from activity a) b where b.row_num=1\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ac5b885c-f43f-4189-b6b0-54366d54dc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sql_24 = mysql_read_action(sql_query_24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1ace6be3-4a45-4f73-adb3-3256ebfef03a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+-------+\n",
      "|player_id|first_login|row_num|\n",
      "+---------+-----------+-------+\n",
      "|        1| 2016-03-01|      1|\n",
      "|        2| 2017-06-25|      1|\n",
      "|        3| 2016-03-02|      1|\n",
      "+---------+-----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sql_24.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "27ebe23b-4b28-4641-b8df-1afbd3fd9dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d50f9e7e-5283-4ede-8037-647732386573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+----------+------------+\n",
      "|player_id|device_id|event_date|games_played|\n",
      "+---------+---------+----------+------------+\n",
      "|        1|        2|2016-03-01|           5|\n",
      "|        1|        2|2016-05-02|           6|\n",
      "|        2|        3|2017-06-25|           1|\n",
      "|        3|        1|2016-03-02|           0|\n",
      "|        3|        4|2018-07-03|           5|\n",
      "+---------+---------+----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "activities_query = \"select * from activity\"\n",
    "activity_df = mysql_read_action(activities_query)\n",
    "activity_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "db924584-ac2b-4162-bb8a-ffbfc8a7d780",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, row_number\n",
    "from pyspark.sql.window import Window\n",
    "window_s = Window.partitionBy(\"player_id\")\n",
    "df_filtered_24 = activity_df.withColumn(\"row_number\", row_number().over(window_s.orderBy(\"event_date\"))).where(col(\"row_number\")==1).select(\"player_id\", \"event_date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "45cdd944-7815-4493-8214-a476b0cb084e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+\n",
      "|player_id|event_date|\n",
      "+---------+----------+\n",
      "|        1|2016-03-01|\n",
      "|        2|2017-06-25|\n",
      "|        3|2016-03-02|\n",
      "+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_filtered_24.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6229e1-4ac9-4395-ac10-d8b2e3bf48ce",
   "metadata": {},
   "source": [
    "### 25. Write an SQL query to report the device that is first logged in for each player."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "63276d3d-ed08-4ec6-813d-4df005348536",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_25 = activity_df.withColumn(\"row_number\", row_number().over(window_s.orderBy(\"event_date\"))).where(col(\"row_number\")==1).select(\"player_id\", \"device_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a510ebc9-cfa4-4087-887f-7570e3bfe6de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+\n",
      "|player_id|device_id|\n",
      "+---------+---------+\n",
      "|        1|        2|\n",
      "|        2|        3|\n",
      "|        3|        1|\n",
      "+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_filtered_25.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4bd710-d766-4156-9e1f-34fe6267557a",
   "metadata": {},
   "source": [
    "### 26. Write an SQL query to get the names of products that have at least 100 units ordered in February 2020 and their amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "355f1510-0fd3-478d-b3a7-69bc6a380b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query_26 = \"\"\"\n",
    "select \n",
    "p.product_id,\n",
    "p.product_name\n",
    "from products p inner join\n",
    "(select\n",
    "a.product_id,\n",
    "sum(a.unit) as total_units\n",
    "from(\n",
    "select \n",
    "o.product_id,\n",
    "extract(year from o.order_date) as _year,\n",
    "extract(month from o.order_date) as _month,\n",
    "o.unit\n",
    "from orders o where extract(year from o.order_date)=2020 and extract(month from o.order_date)=2) a group by a.product_id having total_units>=100) b on p.product_id=b.product_id\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "68afb3b5-e2fe-4410-92df-9ddfd79beaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sql_26 = mysql_read_action(sql_query_26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "91a96d7b-f875-47dc-9d7a-9bbc9290a091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+\n",
      "|product_id|      product_name|\n",
      "+----------+------------------+\n",
      "|         1|Leetcode Solutions|\n",
      "|         5|     Leetco de Kit|\n",
      "+----------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sql_26.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7d792869-324a-4343-812a-b83c1927ff45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyspark solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "069c0f1d-1308-4583-baf9-e18271be2dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_query = \"select * from orders\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f76b19a0-7ef4-478d-a95f-1a3083dc69cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_df = mysql_read_action(orders_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f9a90456-0a39-46ca-b626-32e299a0414b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----+\n",
      "|product_id|order_date|unit|\n",
      "+----------+----------+----+\n",
      "|         1|2020-02-05|  60|\n",
      "|         1|2020-02-10|  70|\n",
      "|         2|2020-01-18|  30|\n",
      "|         2|2020-02-11|  80|\n",
      "|         3|2020-02-17|   2|\n",
      "|         3|2020-02-24|   3|\n",
      "|         4|2020-03-01|  20|\n",
      "|         4|2020-03-04|  30|\n",
      "|         4|2020-03-04|  60|\n",
      "|         5|2020-02-25|  50|\n",
      "|         5|2020-02-27|  50|\n",
      "|         5|2020-03-01|  50|\n",
      "+----------+----------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "19bd31ef-4401-4aa7-83a3-723a08b9d999",
   "metadata": {},
   "outputs": [],
   "source": [
    "products_query = \"select * from products\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "bfc57b0e-91b7-4ba6-9f45-5d421b8f3aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "products_df = mysql_read_action(products_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8ed4de6e-4df7-465d-9cad-7fdb8a6aa254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+----------------+\n",
      "|product_id|        product_name|product_category|\n",
      "+----------+--------------------+----------------+\n",
      "|         1|  Leetcode Solutions|            Book|\n",
      "|         2|Jewels of Stringo...|            Book|\n",
      "|         3|                  HP|          Laptop|\n",
      "|         4|              Lenovo|          Laptop|\n",
      "|         5|       Leetco de Kit|         T-shirt|\n",
      "+----------+--------------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "products_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8c1046c6-ee72-456f-81c5-f459de127578",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import extract, month, year, lit, sum as _sum\n",
    "df_filtered_26_1 = orders_df.select(orders_df.product_id, col('unit'),extract(lit(\"month\"), orders_df.order_date).alias(\"month\"), extract(lit(\"year\"), orders_df.order_date).alias(\"year\"))\\\n",
    "                            .filter((col(\"month\")==2) & (col(\"year\")==2020))\\\n",
    "                            .groupby(\"product_id\")\\\n",
    "                            .agg(_sum(col('unit')).alias(\"total_units\"))\\\n",
    "                            .where(col(\"total_units\")>=100)\\\n",
    "                            .join(products_df, orders_df.product_id==products_df.product_id, how=\"inner\")\\\n",
    "                            .select(products_df.product_id, products_df.product_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c5c7559c-99cb-4ab3-b1f2-666be458d39d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+\n",
      "|product_id|      product_name|\n",
      "+----------+------------------+\n",
      "|         1|Leetcode Solutions|\n",
      "|         5|     Leetco de Kit|\n",
      "+----------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_filtered_26_1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e534c4e-f5a7-4e58-b737-9127394cd72a",
   "metadata": {},
   "source": [
    "### Write an SQL query to find the users who have valid emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "bf8f377b-b970-4ee0-93dd-a8015dbfd871",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query_27 = \"\"\"select * from users where mail rlike '^[a-zA-Z][a-zA-Z0-9_.-]*@leetcode.com$'\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "6ab2590d-3d5a-4fbc-aec2-a19f6d884c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sql_27 = mysql_read_action(sql_query_27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "073de5d9-31b1-48c9-a5dd-e2d0765527e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+--------------------+\n",
      "|user_id|     name|                mail|\n",
      "+-------+---------+--------------------+\n",
      "|      1|  Winston|winston@leetcode.com|\n",
      "|      3|Annabelle| bella-@leetcode.com|\n",
      "|      4|    Sally|sally.come@leetco...|\n",
      "+-------+---------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sql_27.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "ed61f4a5-23e7-4bc3-84af-8acfa6178afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "34f15888-a5f3-4f82-b8b6-03a61667e667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+--------------------+\n",
      "|user_id|     name|                mail|\n",
      "+-------+---------+--------------------+\n",
      "|      1|  Winston|winston@leetcode.com|\n",
      "|      2| Jonathan|     jonathanisgreat|\n",
      "|      3|Annabelle| bella-@leetcode.com|\n",
      "|      4|    Sally|sally.come@leetco...|\n",
      "|      5|   Marwan|quarz#2020@leetco...|\n",
      "|      6|    David|   david69@gmail.com|\n",
      "|      7|  Shapiro| .shapo@leetcode.com|\n",
      "+-------+---------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users_query = \"select * from users\"\n",
    "users_df = mysql_read_action(users_query)\n",
    "users_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "13f1ef89-bcd0-4e57-8b54-e148dfe4eb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_27 = users_df.filter(col(\"mail\").rlike(\"^[a-zA-Z][a-zA-Z0-9_.-]*@leetcode.com$\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "9b5b6794-bc5b-402b-be7f-fb016d41f844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+--------------------+\n",
      "|user_id|     name|                mail|\n",
      "+-------+---------+--------------------+\n",
      "|      1|  Winston|winston@leetcode.com|\n",
      "|      3|Annabelle| bella-@leetcode.com|\n",
      "|      4|    Sally|sally.come@leetco...|\n",
      "+-------+---------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_filtered_27.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c815ebd4-28e4-4c7d-974f-b013e89f9832",
   "metadata": {},
   "source": [
    "### 28. Write an SQL query to report the customer_id and customer_name of customers who have spent at least $100 in each month of June and July 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "93dd615e-db2e-4009-9bc4-859801837722",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query_28 = \"\"\"\n",
    "select o.customer_id, c.name\n",
    "from Customers c, Product p, Orders1 o\n",
    "where c.customer_id = o.customer_id and p.product_id = o.product_id\n",
    "group by o.customer_id\n",
    "having\n",
    "(\n",
    "sum(case when o.order_date like '2020-06%' then o.quantity*p.price\n",
    "else 0 end) >= 100\n",
    "and\n",
    "sum(case when o.order_date like '2020-07%' then o.quantity*p.price\n",
    "else 0 end) >= 100\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "a72c0b77-ed78-475a-a870-5cf82a414ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sql_28 = mysql_read_action(sql_query_28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "96c36c27-b7ef-42f2-ab68-fd1149d2af42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+\n",
      "|customer_id|   name|\n",
      "+-----------+-------+\n",
      "|          1|Winston|\n",
      "+-----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sql_28.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "4a562da4-5a8f-4186-9a6a-a2431d1c96a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark sulution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "205c4577-04cb-4053-9c8e-d63379069329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+-------+\n",
      "|customer_id|    name|country|\n",
      "+-----------+--------+-------+\n",
      "|          1| Winston|    USA|\n",
      "|          2|Jonathan|   Peru|\n",
      "|          3|Moustafa|  Egypt|\n",
      "+-----------+--------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "customers_query = \"select *from customers\"\n",
    "customers_df = mysql_read_action(customers_query)\n",
    "customers_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "416fa0e7-7d27-4d32-9d08-ce105fe81351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+----------+----------+--------+\n",
      "|order_id|customer_id|product_id|order_date|quantity|\n",
      "+--------+-----------+----------+----------+--------+\n",
      "|       1|          1|        10|2020-06-10|       1|\n",
      "|       2|          1|        20|2020-07-01|       1|\n",
      "|       3|          1|        30|2020-07-08|       2|\n",
      "|       4|          2|        10|2020-06-15|       2|\n",
      "|       5|          2|        40|2020-07-01|      10|\n",
      "|       6|          3|        20|2020-06-24|       2|\n",
      "|       7|          3|        30|2020-06-25|       2|\n",
      "|       9|          3|        30|2020-05-08|       3|\n",
      "+--------+-----------+----------+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders1_query = \"select *from orders1\"\n",
    "orders1_df = mysql_read_action(orders1_query)\n",
    "orders1_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c6754f97-4e4c-45cb-a47e-5b0504c9cbab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+-----+\n",
      "|product_id|description|price|\n",
      "+----------+-----------+-----+\n",
      "|        10|   LC Phone|  300|\n",
      "|        20|  LCT-Shirt|   10|\n",
      "|        30|    LC Book|   45|\n",
      "|        40|LC Keychain|    2|\n",
      "+----------+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "product_query = \"select *from product\"\n",
    "product_df = mysql_read_action(product_query)\n",
    "product_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "ee980b72-ab96-4a57-9fba-e8e7962c514a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_28_1 = orders1_df.join(customers_df, customers_df.customer_id==orders1_df.customer_id, how=\"left\")\\\n",
    "                             .select(orders1_df.order_id, customers_df.customer_id, orders1_df.product_id, orders1_df.order_date, orders1_df.quantity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "7a51516e-f27c-402e-911c-fdee331313e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+----------+----------+--------+\n",
      "|order_id|customer_id|product_id|order_date|quantity|\n",
      "+--------+-----------+----------+----------+--------+\n",
      "|       1|          1|        10|2020-06-10|       1|\n",
      "|       2|          1|        20|2020-07-01|       1|\n",
      "|       3|          1|        30|2020-07-08|       2|\n",
      "|       6|          3|        20|2020-06-24|       2|\n",
      "|       7|          3|        30|2020-06-25|       2|\n",
      "|       9|          3|        30|2020-05-08|       3|\n",
      "|       4|          2|        10|2020-06-15|       2|\n",
      "|       5|          2|        40|2020-07-01|      10|\n",
      "+--------+-----------+----------+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_filtered_28_1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "a2c9c50b-c432-40a9-9fd6-4a2769dbcb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_28_2 = df_filtered_28_1.join(product_df, product_df.product_id==df_filtered_28_1.product_id, how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "844b08f4-12f4-489e-836c-7da54a82fb1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+----------+----------+--------+----------+-----------+-----+\n",
      "|order_id|customer_id|product_id|order_date|quantity|product_id|description|price|\n",
      "+--------+-----------+----------+----------+--------+----------+-----------+-----+\n",
      "|       1|          1|        10|2020-06-10|       1|        10|   LC Phone|  300|\n",
      "|       2|          1|        20|2020-07-01|       1|        20|  LCT-Shirt|   10|\n",
      "|       3|          1|        30|2020-07-08|       2|        30|    LC Book|   45|\n",
      "|       6|          3|        20|2020-06-24|       2|        20|  LCT-Shirt|   10|\n",
      "|       7|          3|        30|2020-06-25|       2|        30|    LC Book|   45|\n",
      "|       9|          3|        30|2020-05-08|       3|        30|    LC Book|   45|\n",
      "|       4|          2|        10|2020-06-15|       2|        10|   LC Phone|  300|\n",
      "|       5|          2|        40|2020-07-01|      10|        40|LC Keychain|    2|\n",
      "+--------+-----------+----------+----------+--------+----------+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_filtered_28_2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "587a66b6-fffa-48e3-9bc5-4b6fa4dcb5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, when, sum as _sum, expr\n",
    "\n",
    "# Step 1: Join Customers, Orders1, and Product\n",
    "joined_df = customers_df.alias(\"c\") \\\n",
    "    .join(orders1_df.alias(\"o\"), col(\"c.customer_id\") == col(\"o.customer_id\")) \\\n",
    "    .join(product_df.alias(\"p\"), col(\"o.product_id\") == col(\"p.product_id\"))\n",
    "\n",
    "# Step 2: Add total price per order\n",
    "with_price = joined_df.withColumn(\"total_price\", col(\"o.quantity\") * col(\"p.price\"))\n",
    "\n",
    "# Step 3: Conditional aggregation\n",
    "df_filtered_28 = with_price.groupBy(\"o.customer_id\", \"c.name\").agg(\n",
    "    _sum(when(col(\"o.order_date\").like(\"2020-06%\"), col(\"total_price\")).otherwise(0)).alias(\"june_total\"),\n",
    "    _sum(when(col(\"o.order_date\").like(\"2020-07%\"), col(\"total_price\")).otherwise(0)).alias(\"july_total\")\n",
    ").filter(\n",
    "    (col(\"june_total\") >= 100) & (col(\"july_total\") >= 100)\n",
    ").select(\"customer_id\", \"name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "42fdf69d-8e8c-4016-9888-72f4af3dadd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+\n",
      "|customer_id|   name|\n",
      "+-----------+-------+\n",
      "|          1|Winston|\n",
      "+-----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_filtered_28.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f869e4b-a0e4-40df-b656-e6814be6f36a",
   "metadata": {},
   "source": [
    "### 29. Write an SQL query to report the distinct titles of the kid-friendly movies streamed in June 2020. Return the result table in any order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "f3141c17-909a-4976-8f13-dc6d9b611207",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query_29 = \"\"\"\n",
    "select c.title from content c where c.Kids_content=\"Y\" and c.content_type = 'Movies' and c.content_id in(\n",
    "select \n",
    "tv.content_id\n",
    "from tvprogram tv where tv.program_date like \"2020-06%\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "9a914ec3-ec1b-4e37-8781-c979dacc7cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sql_29 = mysql_read_action(sql_query_29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "a0e7abfa-4c12-4d88-902f-1ad7082ad7e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|  title|\n",
      "+-------+\n",
      "|Aladdin|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sql_29.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "57dd2ccd-9672-4180-ae24-9b2470df0436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "fdf8c3b8-9242-4663-825a-2e1fc1d600f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+----------+\n",
      "|program_date|content_id|   channel|\n",
      "+------------+----------+----------+\n",
      "|  2020-05-11|         2|LC-Channel|\n",
      "|  2020-05-12|         3|LC-Channel|\n",
      "|  2020-05-13|         4| Disney Ch|\n",
      "|  2020-06-10|         1|LC-Channel|\n",
      "|  2020-06-18|         4| Disney Ch|\n",
      "|  2020-07-15|         5| Disney Ch|\n",
      "+------------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tvProgram_query = \"select * from tvprogram\"\n",
    "tvProgram_df = mysql_read_action(tvProgram_query)\n",
    "tvProgram_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "d25f9980-ad32-40f4-86da-e811de23330d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+------------+------------+\n",
      "|content_id|         title|Kids_content|content_type|\n",
      "+----------+--------------+------------+------------+\n",
      "|         1|Leetcode Movie|           N|      Movies|\n",
      "|         2|  Alg.for Kids|           Y|      Series|\n",
      "|         3|  DatabaseSols|           N|      Series|\n",
      "|         4|       Aladdin|           Y|      Movies|\n",
      "|         5|    Cinderella|           Y|      Movies|\n",
      "+----------+--------------+------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "content_query = \"select * from content\"\n",
    "content_df = mysql_read_action(content_query)\n",
    "content_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "add8f5f0-32e9-4a6c-ba79-4e4ba849169b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_29 = content_df.filter((content_df.Kids_content==\"Y\") & (content_df.content_type==\"Movies\"))\\\n",
    "                           .join(tvProgram_df, content_df.content_id==tvProgram_df.content_id)\\\n",
    "                           .filter(tvProgram_df.program_date.rlike(\"^2020-06\")).select(\"title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "37ca385c-e7ba-443a-8058-07b186f35889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|  title|\n",
      "+-------+\n",
      "|Aladdin|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_filtered_29.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cf6863-391a-4ab7-9015-18445fe8d99e",
   "metadata": {},
   "source": [
    "### 30.Write an SQL query to find the npv of each query of the Queries table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "1b817189-b457-413e-a636-53d1bee56758",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query_30 = \"\"\"\n",
    "select q.id, q.year, COALESCE(n.npv, 0) as npv \n",
    "from queries q \n",
    "left join npv n \n",
    "on q.id=n.id and q.year=n.year\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "8e77c676-c6ed-4366-b024-506696495ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sql_30 = mysql_read_action(sql_query_30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "c3dcd0c4-98e3-49ad-9786-fb04566365f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+---+\n",
      "| id|year|npv|\n",
      "+---+----+---+\n",
      "|  1|2019|113|\n",
      "|  2|2008|121|\n",
      "|  3|2009| 12|\n",
      "|  7|2018|  0|\n",
      "|  7|2019|  0|\n",
      "|  7|2020| 30|\n",
      "| 13|2019| 40|\n",
      "+---+----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sql_30.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "ff652412-6bc8-4f2a-b5db-996a8a47052b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyspark solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "740d3c13-50aa-4fc7-b4cf-b94c761b23d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+---+\n",
      "| id|year|npv|\n",
      "+---+----+---+\n",
      "|  1|2018|100|\n",
      "|  1|2019|113|\n",
      "|  2|2008|121|\n",
      "|  3|2009| 12|\n",
      "|  7|2019|  0|\n",
      "|  7|2020| 30|\n",
      "| 11|2020| 99|\n",
      "| 13|2019| 40|\n",
      "+---+----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "npv_query = \"select * from npv\"\n",
    "npv_df = mysql_read_action(npv_query)\n",
    "npv_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "135a85fa-8190-4887-a557-8e0932827c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+\n",
      "| id|year|\n",
      "+---+----+\n",
      "|  1|2019|\n",
      "|  2|2008|\n",
      "|  3|2009|\n",
      "|  7|2018|\n",
      "|  7|2019|\n",
      "|  7|2020|\n",
      "| 13|2019|\n",
      "+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "queries_query = \"select * from queries\"\n",
    "queries_df = mysql_read_action(queries_query)\n",
    "queries_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "239fcbf7-11c4-45bc-ab88-1ead6ef5a922",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import coalesce, lit\n",
    "\n",
    "# Perform the left join\n",
    "joined_df = queries_df.join(\n",
    "    npv_df,\n",
    "    on=(queries_df.id == npv_df.id) & (queries_df.year == npv_df.year),\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Replace nulls in 'npv' with 0 using coalesce\n",
    "df_filtered_30 = joined_df.select(\n",
    "    queries_df.id,\n",
    "    queries_df.year,\n",
    "    coalesce(npv_df.npv, lit(0)).alias(\"npv\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "fa9015b6-3053-40c7-a7a5-edffc27e0d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+---+\n",
      "| id|year|npv|\n",
      "+---+----+---+\n",
      "|  7|2018|  0|\n",
      "|  7|2020| 30|\n",
      "|  2|2008|121|\n",
      "|  1|2019|113|\n",
      "|  7|2019|  0|\n",
      "| 13|2019| 40|\n",
      "|  3|2009| 12|\n",
      "+---+----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_filtered_30.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "e7d0a5e1-1cd0-4563-9e4d-525802b7bd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 31 duplicate quation of 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a258dee-ebfa-4ebd-99c3-041ad32d7a5a",
   "metadata": {},
   "source": [
    "### 32. Write an SQL query to show the unique ID of each user, If a user does not have a unique ID replace just show null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "fef2f8ad-6f0b-457e-a90e-f223f37e9dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+\n",
      "|    name|unique_id|\n",
      "+--------+---------+\n",
      "|   Alice|     NULL|\n",
      "|Jonathan|        1|\n",
      "|     Bob|     NULL|\n",
      "|    Meir|        2|\n",
      "| Winston|        3|\n",
      "+--------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql_query_32 = \"select e.name, u.unique_id from Employees e left join EmployeeUNI u on u.id=e.id\"\n",
    "df_sql_32 = mysql_read_action(sql_query_32)\n",
    "df_sql_32.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "274b23a4-5de1-47e3-b1f6-1603b639d92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "dd3c44ab-bad7-46d8-939c-45512e383445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+\n",
      "| id|    name|\n",
      "+---+--------+\n",
      "|  1|   Alice|\n",
      "|  3|Jonathan|\n",
      "|  7|     Bob|\n",
      "| 11|    Meir|\n",
      "| 90| Winston|\n",
      "+---+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employees_query = \"select * from employees\"\n",
    "employees_df = mysql_read_action(employees_query)\n",
    "employees_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "5d5251fe-1488-41cd-b605-69795a53b4e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+\n",
      "| id|unique_id|\n",
      "+---+---------+\n",
      "|  3|        1|\n",
      "| 11|        2|\n",
      "| 90|        3|\n",
      "+---+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employeeuni_query = \"select * from employeeuni\"\n",
    "employeeuni_df = mysql_read_action(employeeuni_query)\n",
    "employeeuni_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "f711fbd9-0ad7-4e65-b327-9c5ca73732a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_32 = employees_df.join(employeeuni_df, on=\"id\", how=\"left\").select(employees_df.name, employeeuni_df.unique_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "311453c6-2a32-46e6-b948-f83f12be5171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+\n",
      "|    name|unique_id|\n",
      "+--------+---------+\n",
      "|   Alice|     NULL|\n",
      "|Jonathan|        1|\n",
      "|     Bob|     NULL|\n",
      "| Winston|        3|\n",
      "|    Meir|        2|\n",
      "+--------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_filtered_32.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf184110-4daa-4de7-bca8-56276febb036",
   "metadata": {},
   "source": [
    "### 33. Write an SQL query to report the distance travelled by each user. Return the result table ordered by travelled_distance in descending order, if two or more users travelled the same distance, order them by their name in ascending order.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8920150d-0d67-4aec-b55e-29fd01e0ea88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+\n",
      "|    name|distance_travelled|\n",
      "+--------+------------------+\n",
      "|   Elvis|               450|\n",
      "|     Lee|               450|\n",
      "|     Bob|               317|\n",
      "|Jonathan|               312|\n",
      "|    Alex|               222|\n",
      "|   Alice|               120|\n",
      "|  Donald|                 0|\n",
      "+--------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql_query_33 = \"select u.name, coalesce(sum(r.distance), 0) as distance_travelled from users1 u left join rides r on u.id=r.user_id group by u.name order by distance_travelled desc, u.name asc\"\n",
    "df_sql_33 = mysql_read_action(sql_query_33)\n",
    "df_sql_33.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8c8267b1-6753-41c2-8d41-e72e32ebc3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyspark solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "cdbcbcdf-1a68-4f9a-8bfc-672e41453e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+\n",
      "| id|    name|\n",
      "+---+--------+\n",
      "|  1|   Alice|\n",
      "|  2|     Bob|\n",
      "|  3|    Alex|\n",
      "|  4|  Donald|\n",
      "|  7|     Lee|\n",
      "| 13|Jonathan|\n",
      "| 19|   Elvis|\n",
      "+---+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users1_query = \"select * from users1\"\n",
    "users1_df = mysql_read_action(users1_query)\n",
    "users1_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "557bfb11-3cf7-488b-9974-8085656af748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+--------+\n",
      "| id|user_id|distance|\n",
      "+---+-------+--------+\n",
      "|  1|      1|     120|\n",
      "|  2|      2|     317|\n",
      "|  3|      3|     222|\n",
      "|  4|      7|     100|\n",
      "|  5|     13|     312|\n",
      "|  6|     19|      50|\n",
      "|  7|      7|     120|\n",
      "|  8|     19|     400|\n",
      "|  9|      7|     230|\n",
      "+---+-------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rides_query = \"select * from rides\"\n",
    "rides_df = mysql_read_action(rides_query)\n",
    "rides_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ad886f69-04fe-40e2-9a09-5e038a40c066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+\n",
      "|    name|distance_travelled|\n",
      "+--------+------------------+\n",
      "|   Elvis|               450|\n",
      "|     Lee|               450|\n",
      "|     Bob|               317|\n",
      "|Jonathan|               312|\n",
      "|    Alex|               222|\n",
      "|   Alice|               120|\n",
      "|  Donald|                 0|\n",
      "+--------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Assuming users1_df and rides_df are your DataFrames\n",
    "\n",
    "# Join users and rides\n",
    "joined_df = users1_df.join(rides_df, users1_df.id == rides_df.user_id, how=\"left\")\n",
    "\n",
    "# Group by name and aggregate distance\n",
    "df_filtered_33 = (\n",
    "    joined_df\n",
    "    .groupBy(\"name\")\n",
    "    .agg(F.coalesce(F.sum(\"distance\"), F.lit(0)).alias(\"distance_travelled\"))\n",
    "    .orderBy(F.desc(\"distance_travelled\"), F.asc(\"name\"))\n",
    ")\n",
    "\n",
    "# To show result\n",
    "df_filtered_33.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6f440e-7873-4aa7-b979-2f91164f13d3",
   "metadata": {},
   "source": [
    "### 34.Write an SQL query to get the names of products that have at least 100 units ordered in February 2020 and their amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69a6d3fa-7d02-44d7-869d-b0dc35b15f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query_34 = \"\"\"\n",
    "SELECT a.product_name, SUM(unit) AS unit \n",
    "FROM Products1 a \n",
    "LEFT JOIN Orders2 b \n",
    "  ON a.product_id = b.product_id \n",
    "WHERE b.order_date BETWEEN '2020-02-01' AND '2020-02-29' \n",
    "GROUP BY a.product_id \n",
    "HAVING SUM(unit) >= 100\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1af3bf31-abd3-43d8-bdf9-a4bdd3c0133b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sql_34 = mysql_read_action(sql_query_34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c1e8b94-3c1e-45b6-bbb1-45e40d53799a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+\n",
      "|        product_name|unit|\n",
      "+--------------------+----+\n",
      "|  Leetcode Solutions| 520|\n",
      "|Jewels of Stringo...| 320|\n",
      "|        Leetcode Kit| 400|\n",
      "+--------------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sql_34.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a3333f3-c21f-4924-b1ed-f61493bdd9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyspark solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9dbb88c7-2ef7-44fd-89f2-88982632ca4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+----------------+\n",
      "|product_id|        product_name|product_category|\n",
      "+----------+--------------------+----------------+\n",
      "|         1|  Leetcode Solutions|            Book|\n",
      "|         2|Jewels of Stringo...|            Book|\n",
      "|         3|                  HP|          Laptop|\n",
      "|         4|              Lenovo|          Laptop|\n",
      "|         5|        Leetcode Kit|         T-shirt|\n",
      "+----------+--------------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "products_1_query = \"select * from products1\"\n",
    "product_1_df = mysql_read_action(products_1_query)\n",
    "product_1_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c2d2d0e-efd6-445c-86cf-938a5442c9dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----+\n",
      "|product_id|order_date|unit|\n",
      "+----------+----------+----+\n",
      "|         1|2020-02-05|  60|\n",
      "|         1|2020-02-10|  70|\n",
      "|         2|2020-01-18|  30|\n",
      "|         2|2020-02-11|  80|\n",
      "|         3|2020-02-17|   2|\n",
      "|         3|2020-02-24|   3|\n",
      "|         4|2020-03-01|  20|\n",
      "|         4|2020-03-04|  30|\n",
      "|         4|2020-03-04|  60|\n",
      "|         5|2020-02-25|  50|\n",
      "|         5|2020-02-27|  50|\n",
      "|         5|2020-03-01|  50|\n",
      "|         1|2020-02-05|  60|\n",
      "|         1|2020-02-10|  70|\n",
      "|         2|2020-01-18|  30|\n",
      "|         2|2020-02-11|  80|\n",
      "|         3|2020-02-17|   2|\n",
      "|         3|2020-02-24|   3|\n",
      "|         4|2020-03-01|  20|\n",
      "|         4|2020-03-04|  30|\n",
      "+----------+----------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders_2_query = \"select * from orders2\"\n",
    "orders_2_df = mysql_read_action(orders_2_query)\n",
    "orders_2_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb9d23d4-ee87-4b38-973a-eebffff1b102",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import sum as _sum, col\n",
    "df_filtered_34 = product_1_df.join(orders_2_df, product_1_df.product_id==orders_2_df.product_id)\\\n",
    "                             .where(orders_2_df.order_date.between(\"2020-02-01\", \"2020-02-29\"))\\\n",
    "                             .groupBy(\"product_name\").agg(_sum(col(\"unit\")).alias(\"units\")).filter(col(\"units\")>100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d9d64c58-5620-48e0-ad5b-7c5099dda755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|        product_name|units|\n",
      "+--------------------+-----+\n",
      "|Jewels of Stringo...|  320|\n",
      "|        Leetcode Kit|  400|\n",
      "|  Leetcode Solutions|  520|\n",
      "+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_filtered_34.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4f1b38-36af-4d75-932f-bd541745ef86",
   "metadata": {},
   "source": [
    "### 35. Write an SQL query to:\n",
    "### ● Find the name of the user who has rated the greatest number of movies. In case of a tie,\n",
    "### return the lexicographically smaller user name.\n",
    "### ● Find the movie name with the highest average rating in February 2020. In case of a tie, return\n",
    "### the lexicographically smaller movie name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4866fa95-b975-4cc8-8b74-c42ceb024f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|    name|\n",
      "+--------+\n",
      "|  Daniel|\n",
      "|Frozen 2|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql_query_35 = \"\"\"\n",
    "(select \n",
    "u.name\n",
    "from MovieRating m left join users2 u on m.user_id=u.user_id group by u.name order by count(*) desc, u.name asc limit 1)\n",
    "union \n",
    "(select \n",
    "title\n",
    "from movierating mr right join Movies mv on mr.movie_id=mv.movie_id where mr.created_at like \"2020-02%\" group by mv.movie_id order by avg(rating) desc, mv.title ASC limit 1)\n",
    "\"\"\"\n",
    "df_sql_35 = mysql_read_action(sql_query_35)\n",
    "df_sql_35.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ae315365-8fb4-41a0-8b3e-c74e0fc9ee39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyspark solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1e64491b-c638-46dc-98c3-e2566202bcd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+\n",
      "|movie_id|   title|\n",
      "+--------+--------+\n",
      "|       1|Avengers|\n",
      "|       2|Frozen 2|\n",
      "|       3|   Joker|\n",
      "+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies_query = \"select * from movies\"\n",
    "movies_df = mysql_read_action(movies_query)\n",
    "movies_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7afbe2a1-f887-4a34-91e1-b8589235a95d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+\n",
      "|user_id|  name|\n",
      "+-------+------+\n",
      "|      1|Daniel|\n",
      "|      2|Monica|\n",
      "|      3| Maria|\n",
      "|      4| James|\n",
      "+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users2_query = \"select * from users2\"\n",
    "users2_df = mysql_read_action(users2_query)\n",
    "users2_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0eeac153-fabc-4d66-9fa3-8049856d5956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+------+----------+\n",
      "|movie_id|user_id|rating|created_at|\n",
      "+--------+-------+------+----------+\n",
      "|       1|      1|     3|2020-01-12|\n",
      "|       1|      2|     4|2020-02-11|\n",
      "|       1|      3|     2|2020-02-12|\n",
      "|       1|      4|     1|2020-01-01|\n",
      "|       2|      1|     5|2020-02-17|\n",
      "|       2|      2|     2|2020-02-01|\n",
      "|       2|      3|     2|2020-03-01|\n",
      "|       3|      1|     3|2020-02-22|\n",
      "|       3|      2|     4|2020-02-25|\n",
      "+--------+-------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movierating_query = \"select * from movierating\"\n",
    "movierating_df = mysql_read_action(movierating_query)\n",
    "movierating_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "78d4ceca-3042-4b73-97a1-e78c062e6105",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, avg, sum as _sum, count, avg\n",
    "\n",
    "df_filtered_35_1 = movierating_df.join(\n",
    "                        users2_df, \n",
    "                        movierating_df.user_id == users2_df.user_id, \n",
    "                        how=\"left\"\n",
    "                    )\\\n",
    "                    .groupBy(users2_df.name)\\\n",
    "                    .agg(\n",
    "                        count(movierating_df.movie_id).alias(\"movie_count\")\n",
    "                    ).orderBy(count(movierating_df.movie_id).desc(), users2_df.name.asc()).select(\"name\").limit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "81d2e293-c479-43db-96b2-352d77f00cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|  name|\n",
      "+------+\n",
      "|Daniel|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_filtered_35_1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "48478a07-472d-4390-974b-215e9408b2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_35_2 = movierating_df.join(movies_df, movierating_df.movie_id==movies_df.movie_id, how=\"left\")\\\n",
    "                                 .filter(movierating_df.created_at.like(\"2020-02%\"))\\\n",
    "                                 .groupBy(movies_df.title)\\\n",
    "                                 .agg(avg(movierating_df.rating).alias(\"movie_rating\")).orderBy(col(\"movie_rating\").desc(),movies_df.title.asc()).select(\"title\").limit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "75adcae5-3afe-4c4e-a976-4f06bc9427ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|   title|\n",
      "+--------+\n",
      "|Frozen 2|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_filtered_35_2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "430c1829-31ea-47e5-b426-2352452ef940",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_35 = df_filtered_35_1.union(df_filtered_35_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f5cc18b0-47c7-41a5-8a67-5f1b8b5ab0d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|    name|\n",
      "+--------+\n",
      "|  Daniel|\n",
      "|Frozen 2|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_filtered_35.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe82c4a-d2ff-4b0e-892b-265b8b005276",
   "metadata": {},
   "source": [
    "### 36 Write an SQL query to report the distance travelled by each user. Return the result table ordered by travelled_distance in descending order, if two or more users travelled the same distance, order them by their name in ascending orde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "fd0303b7-d06a-4b41-8ade-828d4da7f615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 33 quation answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e5827b-675d-4e52-9717-4059f7c84629",
   "metadata": {},
   "source": [
    "## 37. Write an SQL query to show the unique ID of each user, If a user does not have a unique ID replace just show null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "90723144-312d-4293-8c1b-c3e1628d6a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 32 quation answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c4b9c0-5f93-49a4-bbd9-ebf9ea2dde3f",
   "metadata": {},
   "source": [
    "### 38.Write an SQL query to find the id and the name of all students who are enrolled in departments that no longer exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "463dded2-8dfe-4d3f-b799-8e21b49c5c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+\n",
      "| id|   name|\n",
      "+---+-------+\n",
      "|  2|   John|\n",
      "|  3|  Steve|\n",
      "|  4|Jasmine|\n",
      "|  7| Daiana|\n",
      "+---+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql_query_38 = \"select id, name from Students where department_id not in (select id from Departments)\"\n",
    "df_sql_38 = mysql_read_action(sql_query_38)\n",
    "df_sql_38.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b89af4d7-db5c-4d9f-ae89-240f01602b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyspark solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "68e31844-7ea8-40d2-8b86-4f9ca0e9e333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+\n",
      "| id|                name|\n",
      "+---+--------------------+\n",
      "|  1|Electrical Engine...|\n",
      "|  7|Computer Engineering|\n",
      "| 13|Business Administ...|\n",
      "+---+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "departments_query = \"select * from departments\"\n",
    "departments_df = mysql_read_action(departments_query)\n",
    "departments_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ef9a8c4e-e871-4dae-8cbb-6eaa5fed4d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-------------+\n",
      "| id|    name|department_id|\n",
      "+---+--------+-------------+\n",
      "|  1|     Bob|            7|\n",
      "|  2|    John|           14|\n",
      "|  3|   Steve|           74|\n",
      "|  4| Jasmine|           77|\n",
      "|  5|Jennifer|           13|\n",
      "|  6|    Luis|            1|\n",
      "|  7|  Daiana|           33|\n",
      "|  8|Jonathan|            7|\n",
      "| 11|Madelynn|            1|\n",
      "| 23|   Alice|            1|\n",
      "+---+--------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "students_query = \"select * from students\"\n",
    "students_df = mysql_read_action(students_query)\n",
    "students_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2abf12e5-46ee-4d47-a82e-42a0dd63296f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_38 = students_df.join(departments_df, students_df.department_id==departments_df.id, how=\"left_anti\").select(students_df.id, students_df.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "20b49898-6195-4e77-9c3a-5670b18f439e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+\n",
      "| id|   name|\n",
      "+---+-------+\n",
      "|  4|Jasmine|\n",
      "|  7| Daiana|\n",
      "|  2|   John|\n",
      "|  3|  Steve|\n",
      "+---+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_filtered_38.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f92fc44-7fe5-43f2-a852-b908c5f0e1e6",
   "metadata": {},
   "source": [
    "### 39 .Write an SQL query to report the number of calls and the total call duration between each pair of distinct persons (person1, person2) where person1 < person2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d3483ca2-feff-4c11-b0e0-54ec7e065df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+----------+--------------+\n",
      "|person1|person2|call_count|total_duration|\n",
      "+-------+-------+----------+--------------+\n",
      "|      1|      2|         2|            70|\n",
      "|      1|      3|         1|            20|\n",
      "|      3|      4|         4|           999|\n",
      "+-------+-------+----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql_query_39 = \"\"\"\n",
    "SELECT LEAST(from_id,to_id) as person1,\n",
    "GREATEST(from_id,to_id) as person2,\n",
    "COUNT(*) as call_count,\n",
    "SUM(duration) as total_duration\n",
    "FROM Calls\n",
    "GROUP BY person1,person2\n",
    "\"\"\"\n",
    "df_sql_39 = mysql_read_action(sql_query_39)\n",
    "df_sql_39.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8bfd594f-916e-4272-b019-637f54d6dfee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+--------+\n",
      "|from_id|to_id|duration|\n",
      "+-------+-----+--------+\n",
      "|      1|    2|      59|\n",
      "|      2|    1|      11|\n",
      "|      1|    3|      20|\n",
      "|      3|    4|     100|\n",
      "|      3|    4|     200|\n",
      "|      3|    4|     200|\n",
      "|      4|    3|     499|\n",
      "+-------+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "calls_query = \"select * from calls\"\n",
    "calls_df = mysql_read_action(calls_query)\n",
    "calls_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "05326abb-1f60-4f3c-8104-b1d7a113e911",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import least, greatest, count, sum as _sum\n",
    "df_filtered_39 = calls_df.select(least(calls_df.from_id, calls_df.to_id).alias(\"person1\"), greatest(calls_df.from_id, calls_df.to_id).alias(\"person2\"), calls_df.duration)\\\n",
    "                         .groupBy(\"person1\", \"person2\")\\\n",
    "                         .agg(count(col(\"person1\")).alias(\"count\"), _sum(calls_df.duration).alias(\"total_duration\"))\\\n",
    "                         .select(\"person1\", \"person2\", \"count\", \"total_duration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "60949d5b-5782-4946-8496-eaa34271059a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----+--------------+\n",
      "|person1|person2|count|total_duration|\n",
      "+-------+-------+-----+--------------+\n",
      "|      1|      2|    2|            70|\n",
      "|      1|      3|    1|            20|\n",
      "|      3|      4|    4|           999|\n",
      "+-------+-------+-----+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_filtered_39.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "335610ad-8d23-4eae-b80e-f5e9f9852f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#40 is duplicate quation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d78035c-8485-4a5c-b4a9-5b5b7d42c65c",
   "metadata": {},
   "source": [
    "### 41.Write an SQL query to report the number of cubic feet of volume the inventory occupies in each warehouse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "a13b1d6e-2303-4a1b-80da-a37dcb2c8601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------+\n",
      "|warehouse_name|volume|\n",
      "+--------------+------+\n",
      "|      LCHouse1| 12250|\n",
      "|      LCHouse2| 20250|\n",
      "|      LCHouse3|   800|\n",
      "+--------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql_query_41 = \"\"\"\n",
    "select name as warehouse_name, sum(units * vol) as volume\n",
    "from Warehouse w\n",
    "join (select product_id, Width*Length*Height as vol\n",
    "from Products2) p\n",
    "on w.product_id = p.product_id\n",
    "group by name\n",
    "\"\"\"\n",
    "df_sql_41 = mysql_read_action(sql_query_41)\n",
    "df_sql_41.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "5f9caa5c-7604-47e0-b075-befacde2cd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "03c87038-3ed9-4d84-9dec-48986f350ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-----+\n",
      "|    name|product_id|units|\n",
      "+--------+----------+-----+\n",
      "|LCHouse1|         1|    1|\n",
      "|LCHouse1|         2|   10|\n",
      "|LCHouse1|         3|    5|\n",
      "|LCHouse2|         1|    2|\n",
      "|LCHouse2|         2|    2|\n",
      "|LCHouse3|         4|    1|\n",
      "+--------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "warehouse_query = \"select * from warehouse\"\n",
    "warehouse_df = mysql_read_action(warehouse_query)\n",
    "warehouse_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "24ba0d84-fc9b-43db-8506-1d328e85d231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+-----+------+------+\n",
      "|product_id|product_name|Width|Length|Height|\n",
      "+----------+------------+-----+------+------+\n",
      "|         1|       LC-TV|    5|    50|    40|\n",
      "|         2| LC-KeyChain|    5|     5|     5|\n",
      "|         3|    LC-Phone|    2|    10|    10|\n",
      "|         4|  LC-T-Shirt|    4|    10|    20|\n",
      "+----------+------------+-----+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "product2_query = \"select * from products2\"\n",
    "products2_df = mysql_read_action(product2_query)\n",
    "products2_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "41b344f6-b7b0-450b-a3da-2b65b9cfcce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_41 = warehouse_df.join(products2_df, warehouse_df.product_id==products2_df.product_id, how=\"left\")\\\n",
    "                        .select(warehouse_df.product_id, warehouse_df.name, \n",
    "                                (warehouse_df.units*(products2_df.Width*products2_df.Length*products2_df.Height)).alias(\"volume\"))\\\n",
    "                        .groupBy(warehouse_df.name)\\\n",
    "                        .agg(_sum(col(\"volume\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "7b216f8f-34f5-41d3-bcc6-8883c349830b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+\n",
      "|    name|sum(volume)|\n",
      "+--------+-----------+\n",
      "|LCHouse2|      20250|\n",
      "|LCHouse3|        800|\n",
      "|LCHouse1|      12250|\n",
      "+--------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_filtered_41.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b860135f-b432-4345-b76d-73c9d9467774",
   "metadata": {},
   "source": [
    "### 42.Write an SQL query to report the difference between the number of apples and oranges sold each day.Return the result table ordered by sale_date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a09f3db9-c18c-4006-a744-41d6eea693db",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query_42 = \"\"\"\n",
    "SELECT \n",
    "  sale_date,\n",
    "  SUM(CASE WHEN fruit = 'apples' THEN sold_num ELSE 0 END) - \n",
    "  SUM(CASE WHEN fruit = 'oranges' THEN sold_num ELSE 0 END) AS diff\n",
    "FROM sales\n",
    "GROUP BY sale_date\n",
    "ORDER BY sale_date\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4afab1c5-f015-4108-8164-4e09b053d02b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+\n",
      "| sale_date|diff|\n",
      "+----------+----+\n",
      "|2020-05-01|   2|\n",
      "|2020-05-02|   0|\n",
      "|2020-05-03|  20|\n",
      "|2020-05-04|  -1|\n",
      "+----------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sql_42 = mysql_read_action(sql_query_42)\n",
    "df_sql_42.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3931b0ee-52f3-4c36-aa3e-be1e2f06faef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+--------+\n",
      "| sale_date|  fruit|sold_num|\n",
      "+----------+-------+--------+\n",
      "|2020-05-01|apples |      10|\n",
      "|2020-05-01|oranges|       8|\n",
      "|2020-05-02|apples |      15|\n",
      "|2020-05-02|oranges|      15|\n",
      "|2020-05-03|apples |      20|\n",
      "|2020-05-03|oranges|       0|\n",
      "|2020-05-04|apples |      15|\n",
      "|2020-05-04|oranges|      16|\n",
      "+----------+-------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# pyspark solution\n",
    "sales_query = \"select * from sales\"\n",
    "sales_df = mysql_read_action(sales_query)\n",
    "sales_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ddbf0175-3995-4e2f-a813-bc19303950f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+------------+----+\n",
      "| sale_date|apples_sold|oranges_sold|diff|\n",
      "+----------+-----------+------------+----+\n",
      "|2020-05-01|         10|           8|   2|\n",
      "|2020-05-02|         15|          15|   0|\n",
      "|2020-05-03|         20|           0|  20|\n",
      "|2020-05-04|         15|          16|  -1|\n",
      "+----------+-----------+------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Compute apples and oranges sold per date\n",
    "result = (\n",
    "    sales_df.groupBy(\"sale_date\")\n",
    "    .agg(\n",
    "        F.sum(F.when(F.col(\"fruit\") == \"apples\", F.col(\"sold_num\")).otherwise(0)).alias(\"apples_sold\"),\n",
    "        F.sum(F.when(F.col(\"fruit\") == \"oranges\", F.col(\"sold_num\")).otherwise(0)).alias(\"oranges_sold\")\n",
    "    )\n",
    "    .withColumn(\"diff\", F.col(\"apples_sold\") - F.col(\"oranges_sold\"))\n",
    "    .orderBy(\"sale_date\")\n",
    ")\n",
    "\n",
    "result.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86aab63-bf7a-4f10-bb2c-f840aa3d21f1",
   "metadata": {},
   "source": [
    "### 43.Write an SQL query to report the fraction of players that logged in again on the day after the day they first logged in, rounded to 2 decimal places. In other words, you need to count the number of players that logged in for at least two consecutive days starting from their first login date, then divide that number by the total number of players.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a65f66a0-470c-41b8-97d1-d342ceaa40dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|fraction|\n",
      "+--------+\n",
      "|    0.33|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql_query_43 = \"\"\"\n",
    "select \n",
    "round(count(distinct a.player_id)/(select count(distinct player_id) from activity1), 2) as fraction\n",
    "from(\n",
    "SELECT \n",
    "  player_id, \n",
    "  event_date,\n",
    "  DATEDIFF(LEAD(event_date) OVER (PARTITION BY player_id ORDER BY event_date), event_date) AS diff\n",
    "FROM activity1) a where a.diff=1\n",
    "\"\"\"\n",
    "df_sql_43 = mysql_read_action(sql_query_43)\n",
    "df_sql_43.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "090d417a-e4a9-46c4-8a07-64620081b75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1fed7aab-937b-40db-ac00-ca6c7f984583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+----------+------------+\n",
      "|player_id|device_id|event_date|games_played|\n",
      "+---------+---------+----------+------------+\n",
      "|        1|        2|2016-03-01|           5|\n",
      "|        1|        2|2016-03-02|           6|\n",
      "|        2|        3|2017-06-25|           1|\n",
      "|        3|        1|2016-03-02|           0|\n",
      "|        3|        4|2018-07-03|           5|\n",
      "+---------+---------+----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "activity1_query = \"select * from activity1\"\n",
    "activity1_df = mysql_read_action(activity1_query)\n",
    "activity1_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "72b9a3db-1695-4bd4-a5bf-10f4ca67e335",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "total_players = activity1_df.select(col(\"player_id\")).distinct().count()\n",
    "window = Window.partitionBy(\"player_id\").orderBy(\"event_date\")\n",
    "filtered_df_43_1 = (activity1_df.select(activity1_df.player_id, activity1_df.event_date)\\\n",
    "                               .withColumn(\"diff\",\n",
    "                               F.datediff(F.lead(col(\"event_date\")).over(window), col(\"event_date\"))).filter(col(\"diff\")==1).select(\"player_id\").count())/total_players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d7f93693-e6b0-4355-9a4f-47b3084877f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df_43_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ed0864-1b13-445a-b113-fde44ae4133f",
   "metadata": {},
   "source": [
    "### 44.Write an SQL query to report the managers with at least five direct reports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "72c5281b-bba7-4332-b44f-5f153a736842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "|name|\n",
      "+----+\n",
      "|John|\n",
      "+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql_query_44 = \"\"\"select \n",
    "e.name\n",
    "from employee e join employee a on e.id=a.managerid group by e.name having count(distinct a.id)>=5\n",
    "\"\"\"\n",
    "df_sql_44 = mysql_read_action(sql_query_44)\n",
    "df_sql_44.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "305a1af8-de0e-4d3b-953a-4574c6972b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyspark solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f90d322e-d708-4aad-a888-ce7ecde4d53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----------+---------+\n",
      "| id| name|department|managerId|\n",
      "+---+-----+----------+---------+\n",
      "|101| John|         A|     NULL|\n",
      "|102|  Dan|         A|      101|\n",
      "|103|James|         A|      101|\n",
      "|104|  Amy|         A|      101|\n",
      "|105| Anne|         A|      101|\n",
      "|106|  Ron|         B|      101|\n",
      "+---+-----+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employee_query = \"select * from employee\"\n",
    "employee_df = mysql_read_action(employee_query)\n",
    "employee_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "909a86e9-4978-459a-88df-09a045777308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+\n",
      "|manager_name|report_count|\n",
      "+------------+------------+\n",
      "|        John|           5|\n",
      "+------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Aliasing\n",
    "a = employee_df.alias(\"a\")\n",
    "b = employee_df.alias(\"b\")\n",
    "\n",
    "# Self join: employee's managerId matches manager's id\n",
    "joined_df = a.join(b, col(\"a.managerId\") == col(\"b.id\"))\n",
    "\n",
    "# Select needed columns before grouping\n",
    "result_df = joined_df.select(\n",
    "    col(\"a.id\").alias(\"employee_id\"),\n",
    "    col(\"b.id\").alias(\"manager_id\"),\n",
    "    col(\"b.name\").alias(\"manager_name\")\n",
    ")\n",
    "\n",
    "# Group by manager_id and manager_name, count reports\n",
    "grouped_df = result_df.groupBy(\"manager_name\").agg(\n",
    "    F.count(\"employee_id\").alias(\"report_count\")\n",
    ")\n",
    "\n",
    "grouped_df.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57262b03-9878-404d-9d24-b91551b56c2c",
   "metadata": {},
   "source": [
    "### 45. Write an SQL query to report the respective department name and number of students majoring in each department for all departments in the Department table (even ones with no current students). Return the result table ordered by student_number in descending order. In case of a tie, order them by dept_name alphabetically.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e1fd7916-5a79-40d4-9eff-832cd4cb47a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+\n",
      "|  dept_name|count_vs|\n",
      "+-----------+--------+\n",
      "|Engineering|       2|\n",
      "|        Law|       0|\n",
      "|    Science|       1|\n",
      "+-----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql_query_45 = \"select d.dept_name, coalesce(count(distinct s.student_id), 0) as count_vs from student s right join department d on s.dept_id=d.dept_id group by d.dept_name order by d.dept_name asc\"\n",
    "df_sql_45 = mysql_read_action(sql_query_45)\n",
    "df_sql_45.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5d508c15-d6b4-4455-a306-719ea5f7916d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyspark solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "437d25fa-e0c0-4b03-baf0-656b8d458258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+------+-------+\n",
      "|student_id|student_name|gender|dept_id|\n",
      "+----------+------------+------+-------+\n",
      "|         1|        Jack|     M|      1|\n",
      "|         2|        Jane|     F|      1|\n",
      "|         3|        Mark|     M|      2|\n",
      "+----------+------------+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "student_query = \"select * from student\"\n",
    "student_df = mysql_read_action(student_query)\n",
    "student_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b8a0e518-2ebd-41bc-8f58-47059b53c536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+\n",
      "|dept_id|  dept_name|\n",
      "+-------+-----------+\n",
      "|      1|Engineering|\n",
      "|      2|    Science|\n",
      "|      3|        Law|\n",
      "+-------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "department_query = \"select * from department\"\n",
    "department_df = mysql_read_action(department_query)\n",
    "department_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ecbfcbb5-13d2-4e01-bb7a-12dfd03f4509",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df_45 = department_df.join(student_df, department_df.dept_id==student_df.dept_id, how=\"left\")\\\n",
    "                              .groupBy(department_df.dept_name).agg(F.count(student_df.student_id).alias(\"count\"))\\\n",
    "                              .orderBy(col(\"count\").desc(),department_df.dept_name.asc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "114be16b-5d82-4d29-92ce-d9201f1146ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|  dept_name|count|\n",
      "+-----------+-----+\n",
      "|Engineering|    2|\n",
      "|    Science|    1|\n",
      "|        Law|    0|\n",
      "+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filtered_df_45.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66653a4f-8321-48c6-bdb0-554472d3e9d2",
   "metadata": {},
   "source": [
    "### 46. Write an SQL query to report the customer ids from the Customer table that bought all the products in the Product table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "fd5cde21-b81d-49e0-b6f4-986504a8baa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|customer_id|\n",
      "+-----------+\n",
      "|          1|\n",
      "|          3|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql_query_46 = \"\"\"\n",
    "select \n",
    "customer_id\n",
    "from customer group by customer_id\n",
    "having count(distinct product_key) = (select count(*) from product1)\n",
    "\"\"\"\n",
    "df_sql_46 = mysql_read_action(sql_query_46)\n",
    "df_sql_46.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "16db8d59-5aab-4a74-903a-cc16c9ea765b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2a2376c9-2f7b-4da5-9390-8f945319efe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+\n",
      "|customer_id|product_key|\n",
      "+-----------+-----------+\n",
      "|          1|          5|\n",
      "|          2|          6|\n",
      "|          3|          5|\n",
      "|          3|          6|\n",
      "|          1|          6|\n",
      "+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "customer_query = \"select * from customer\"\n",
    "customer_df = mysql_read_action(customer_query)\n",
    "customer_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a46fd0e5-63cc-4e91-bf6a-cc0fc76db18c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|product_key|\n",
      "+-----------+\n",
      "|          5|\n",
      "|          6|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "product_query = \"select * from product1\"\n",
    "product_df = mysql_read_action(product_query)\n",
    "product_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "50eaefb5-c349-40b7-86f0-9546c0f4274c",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_key_count = product_df.count()\n",
    "df_filtered_46 = customer_df.groupby(col(\"customer_id\")).agg(F.count(col(\"product_key\")).alias(\"count\"))\\\n",
    "                            .filter(col(\"count\")==product_key_count).select(\"customer_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d249f35e-d9fb-41f7-9551-e64e68070a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|customer_id|\n",
      "+-----------+\n",
      "|          1|\n",
      "|          3|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_filtered_46.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7416c1a-c7f5-43cc-ad95-017d0991cfd3",
   "metadata": {},
   "source": [
    "### 47. Write an SQL query that reports the most experienced employees in each project. In case of a tie, report all employees with the maximum number of experience years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aae0ae69-49c0-4ce9-84aa-6195c75c06d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+\n",
      "|project_id|employee_id|\n",
      "+----------+-----------+\n",
      "|         1|          1|\n",
      "|         1|          3|\n",
      "|         2|          1|\n",
      "+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql_query_47 = \"\"\"\n",
    "select \n",
    "project_id, employee_id from (\n",
    "select \n",
    "p.project_id, e.employee_id, e.experience_years, rank() over (order by e.experience_years desc) as r\n",
    "from EMPLOYEE1 E \n",
    "left join project p \n",
    "on e.employee_id = p.employee_id) o where o.r=1 order by o.project_id asc\n",
    "\"\"\"\n",
    "df_sql_47 = mysql_read_action(sql_query_47)\n",
    "df_sql_47.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9a9d626-bb57-4939-aeb5-fe28233bc068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyspark solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b593e0cd-da64-40d0-ab90-9c476f9c815a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+\n",
      "|project_id|employee_id|\n",
      "+----------+-----------+\n",
      "|         1|          1|\n",
      "|         2|          1|\n",
      "|         1|          2|\n",
      "|         1|          3|\n",
      "|         2|          4|\n",
      "+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "project_query = \"select * from project\"\n",
    "project_df = mysql_read_action(project_query)\n",
    "project_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef461752-5924-49a7-9d4d-da009f90ae6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+----------------+\n",
      "|employee_id|  name|experience_years|\n",
      "+-----------+------+----------------+\n",
      "|          1|Khaled|               3|\n",
      "|          2|   Ali|               2|\n",
      "|          3|  John|               3|\n",
      "|          4|   Doe|               2|\n",
      "+-----------+------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employee1_query = \"select * from employee1\"\n",
    "employee1_df =  mysql_read_action(employee1_query)\n",
    "employee1_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "01224871-545e-4510-b8ce-23c1b52f8851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+\n",
      "|project_id|employee_id|\n",
      "+----------+-----------+\n",
      "|         1|          1|\n",
      "|         1|          3|\n",
      "|         2|          1|\n",
      "+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "window = Window.orderBy(F.col(\"experience_years\").desc())\n",
    "filtered_df_47 = employee1_df.join(project_df, employee1_df.employee_id==project_df.employee_id, how=\"left\")\\\n",
    "                             .withColumn(\"rank\",F.rank().over(window))\\\n",
    "                             .filter(F.col(\"rank\")==1)\\\n",
    "                             .select(project_df.project_id, employee1_df.employee_id)\\\n",
    "                             .orderBy(F.col(\"project_id\").asc())\n",
    "filtered_df_47.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae50b62-b3ac-4916-8e4a-981e5605e3f0",
   "metadata": {},
   "source": [
    "### 48. Write an SQL query that reports the books that have sold less than 10 copies in the last year, excluding books that have been available for less than one month from today. Assume today is 2019-06-23."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d89fa670-70a4-4350-9a73-397fd8167d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+--------------+\n",
      "|book_id|              name|total_quantity|\n",
      "+-------+------------------+--------------+\n",
      "|      1|\"Kalila And Demna\"|             3|\n",
      "|      2|      \"28 Letters\"|             0|\n",
      "|      5|\"The Hunger Games\"|             0|\n",
      "+-------+------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql_query_48 = \"\"\"\n",
    "SELECT \n",
    "  b.book_id,\n",
    "  b.name,\n",
    "  COALESCE(SUM(o.quantity), 0) AS total_quantity\n",
    "FROM books b\n",
    "LEFT JOIN orders3 o \n",
    "  ON b.book_id = o.book_id \n",
    "  AND o.dispatch_date BETWEEN DATE_SUB(DATE '2019-06-23', INTERVAL 1 YEAR)\n",
    "                          AND DATE('2019-06-23')\n",
    "WHERE b.available_from < DATE_SUB(DATE '2019-06-23', INTERVAL 1 MONTH)\n",
    "GROUP BY b.book_id, b.name\n",
    "HAVING total_quantity < 10\n",
    "\"\"\"\n",
    "df_sql_48 = mysql_read_action(sql_query_48)\n",
    "df_sql_48.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9739939a-5d4b-4fc1-9084-5d0ad813024d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b449cd4-51d8-4fd4-a018-6219be476a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+--------+-------------+\n",
      "|order_id|book_id|quantity|dispatch_date|\n",
      "+--------+-------+--------+-------------+\n",
      "|       1|      1|       2|   2018-07-26|\n",
      "|       2|      1|       1|   2018-11-05|\n",
      "|       3|      3|       8|   2019-06-11|\n",
      "|       4|      4|       6|   2019-06-05|\n",
      "|       5|      4|       5|   2019-06-20|\n",
      "|       6|      5|       9|   2009-02-02|\n",
      "|       7|      5|       8|   2010-04-13|\n",
      "+--------+-------+--------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders3_query = \"select * from orders3\"\n",
    "orders3_df = mysql_read_action(orders3_query)\n",
    "orders3_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "908d8dcd-c0ea-450d-8f09-e7d19983168a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+--------------+\n",
      "|book_id|              name|available_from|\n",
      "+-------+------------------+--------------+\n",
      "|      1|\"Kalila And Demna\"|    2010-01-01|\n",
      "|      2|      \"28 Letters\"|    2012-05-12|\n",
      "|      3|      \"The Hobbit\"|    2019-06-10|\n",
      "|      4|  \"13 Reasons Why\"|    2010-01-01|\n",
      "|      5|\"The Hunger Games\"|    2008-09-21|\n",
      "+-------+------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "books_query = \"select * from books\"\n",
    "books_df = mysql_read_action(books_query)\n",
    "books_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d90eba45-e53a-46c2-96b6-a97e2b8a6db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+--------------+\n",
      "|book_id|              name|total_quantity|\n",
      "+-------+------------------+--------------+\n",
      "|      1|\"Kalila And Demna\"|             3|\n",
      "|      5|\"The Hunger Games\"|             0|\n",
      "|      2|      \"28 Letters\"|             0|\n",
      "+-------+------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, sum as _sum, coalesce, lit, to_date, date_sub\n",
    "\n",
    "# Assume books_df and orders3_df are already created DataFrames\n",
    "\n",
    "# Set base analysis date\n",
    "today = to_date(lit('2019-06-23'))\n",
    "\n",
    "# Filter books available for more than 1 month from \"today\"\n",
    "filtered_books = books_df.filter(\n",
    "    col(\"available_from\") < date_sub(today, 30)\n",
    ")\n",
    "\n",
    "# Filter orders within the last year\n",
    "filtered_orders = orders3_df.filter(\n",
    "    (col(\"dispatch_date\") >= date_sub(today, 365)) &\n",
    "    (col(\"dispatch_date\") <= today)\n",
    ")\n",
    "\n",
    "# Left join books with filtered orders\n",
    "joined_df = filtered_books.join(\n",
    "    filtered_orders,\n",
    "    on=\"book_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Group by book and compute total quantity sold\n",
    "result_df = joined_df.groupBy(\"book_id\", \"name\").agg(\n",
    "    coalesce(_sum(\"quantity\"), lit(0)).alias(\"total_quantity\")\n",
    ").filter(col(\"total_quantity\") < 10)\n",
    "\n",
    "# Display result\n",
    "result_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08dd15f3-0691-4faf-9dc4-a6587208e652",
   "metadata": {},
   "source": [
    "### 49. Write a SQL query to find the highest grade with its corresponding course for each student. In case of a tie, you should find the course with the smallest course_id.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4f7492d-d827-4eb9-b2ce-0718ed9b4387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-----+---+\n",
      "|student_id|course_id|grade|  r|\n",
      "+----------+---------+-----+---+\n",
      "|         1|        2|   99|  1|\n",
      "|         2|        2|   95|  1|\n",
      "|         3|        3|   82|  1|\n",
      "+----------+---------+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql_query_49 = \"\"\"\n",
    "select * from (\n",
    "select \n",
    "student_id,\n",
    "course_id,\n",
    "grade,\n",
    "rank() over(partition by student_id order by grade desc,course_id asc) as r\n",
    "from Enrollments) o where o.r=1\n",
    "\"\"\"\n",
    "df_sql_49 = mysql_read_action(sql_query_49)\n",
    "df_sql_49.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3927982f-59c0-4156-a958-acc2361fc9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0a7f1594-9e16-4f0b-a148-6851d5d79656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-----+\n",
      "|student_id|course_id|grade|\n",
      "+----------+---------+-----+\n",
      "|         1|        1|   90|\n",
      "|         1|        2|   99|\n",
      "|         2|        2|   95|\n",
      "|         2|        3|   95|\n",
      "|         3|        1|   80|\n",
      "|         3|        2|   75|\n",
      "|         3|        3|   82|\n",
      "+----------+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "enrollments_query = \"select * from enrollments\"\n",
    "enrollments_df = mysql_read_action(enrollments_query)\n",
    "enrollments_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec537e42-f6e5-4232-921f-1757bf01c594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-----+----+\n",
      "|student_id|course_id|grade|rank|\n",
      "+----------+---------+-----+----+\n",
      "|         1|        2|   99|   1|\n",
      "|         2|        2|   95|   1|\n",
      "|         3|        3|   82|   1|\n",
      "+----------+---------+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql import functions as F\n",
    "window_spec = Window.partitionBy(enrollments_df.student_id).orderBy(enrollments_df.grade.desc(), enrollments_df.course_id.asc())\n",
    "filtered_df_49 = enrollments_df.withColumn(\"rank\", F.rank().over(window_spec)).filter(F.col(\"rank\")==1)\n",
    "filtered_df_49.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf36999e-40b3-41cf-abae-b21c8d9c97fa",
   "metadata": {},
   "source": [
    "#### 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27cfd05d-057f-4326-b36b-42a12aaa64f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+\n",
      "|group_id|player_id|\n",
      "+--------+---------+\n",
      "|       1|       15|\n",
      "|       2|       35|\n",
      "|       3|       40|\n",
      "+--------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql_query_50 = \"\"\"\n",
    "SELECT group_id, player_id\n",
    "FROM (\n",
    "    SELECT \n",
    "        p.group_id,\n",
    "        p.player_id,\n",
    "        SUM(\n",
    "            CASE \n",
    "                WHEN p.player_id = m.first_player THEN m.first_score\n",
    "                WHEN p.player_id = m.second_player THEN m.second_score\n",
    "                ELSE 0\n",
    "            END\n",
    "        ) AS total_score,\n",
    "        ROW_NUMBER() OVER (\n",
    "            PARTITION BY p.group_id \n",
    "            ORDER BY \n",
    "                SUM(\n",
    "                    CASE \n",
    "                        WHEN p.player_id = m.first_player THEN m.first_score\n",
    "                        WHEN p.player_id = m.second_player THEN m.second_score\n",
    "                        ELSE 0\n",
    "                    END\n",
    "                ) DESC,\n",
    "                p.player_id\n",
    "        ) AS rn\n",
    "    FROM Players p\n",
    "    JOIN Matches m ON p.player_id = m.first_player OR p.player_id = m.second_player\n",
    "    GROUP BY p.group_id, p.player_id\n",
    ") ranked\n",
    "WHERE rn = 1\n",
    "ORDER BY group_id\n",
    "\"\"\"\n",
    "df_sql_50 = mysql_read_action(sql_query_50)\n",
    "df_sql_50.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86da771f-38ea-404c-8ee8-f4617209a082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0617443-0e9e-491e-991e-a8c75013d919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+-------------+-----------+------------+\n",
      "|match_id|first_player|second_player|first_score|second_score|\n",
      "+--------+------------+-------------+-----------+------------+\n",
      "|       1|          15|           45|          3|           0|\n",
      "|       2|          30|           25|          1|           2|\n",
      "|       3|          30|           15|          2|           0|\n",
      "|       4|          40|           20|          5|           2|\n",
      "|       5|          35|           50|          1|           1|\n",
      "+--------+------------+-------------+-----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "matches_query = \"select * from Matches\"\n",
    "matches_df = mysql_read_action(matches_query)\n",
    "matches_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3df2909-b43f-4b2c-a26f-0ff84585effe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+\n",
      "|player_id|group_id|\n",
      "+---------+--------+\n",
      "|       10|       2|\n",
      "|       15|       1|\n",
      "|       20|       3|\n",
      "|       25|       1|\n",
      "|       30|       1|\n",
      "|       35|       2|\n",
      "|       40|       3|\n",
      "|       45|       1|\n",
      "|       50|       2|\n",
      "+---------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "players_query = \"select * from players\"\n",
    "players_df = mysql_read_action(players_query)\n",
    "players_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e422b2e-379b-43b5-88b7-08e8844083c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+\n",
      "|group_id|player_id|\n",
      "+--------+---------+\n",
      "|       1|       15|\n",
      "|       2|       35|\n",
      "|       3|       40|\n",
      "+--------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Join Players and Matches where the player is involved\n",
    "joined_df = players_df.alias(\"p\") \\\n",
    "    .join(matches_df.alias(\"m\"),\n",
    "          (F.col(\"p.player_id\") == F.col(\"m.first_player\")) |\n",
    "          (F.col(\"p.player_id\") == F.col(\"m.second_player\")))\n",
    "\n",
    "# Add a column for the score for that player\n",
    "scored_df = joined_df.withColumn(\n",
    "    \"score\",\n",
    "    F.when(F.col(\"p.player_id\") == F.col(\"m.first_player\"), F.col(\"m.first_score\"))\n",
    "     .when(F.col(\"p.player_id\") == F.col(\"m.second_player\"), F.col(\"m.second_score\"))\n",
    "     .otherwise(0)\n",
    ")\n",
    "\n",
    "# Sum scores per group_id and player_id\n",
    "agg_df = scored_df.groupBy(\"p.group_id\", \"p.player_id\") \\\n",
    "    .agg(F.sum(\"score\").alias(\"total_score\"))\n",
    "\n",
    "# Use window to get the top scorer per group\n",
    "window = Window.partitionBy(\"group_id\").orderBy(F.desc(\"total_score\"), F.asc(\"player_id\"))\n",
    "\n",
    "top_players = agg_df.withColumn(\"rank\", F.row_number().over(window)) \\\n",
    "    .filter(F.col(\"rank\") == 1) \\\n",
    "    .select(\"group_id\", \"player_id\")\n",
    "\n",
    "top_players.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68934bd3-ac70-4cbd-ae84-60909c7117ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
